{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks: Application\n",
    "\n",
    "Welcome to Course 4's second assignment! In this notebook, you will:\n",
    "\n",
    "- Create a mood classifer using the TF Keras Sequential API\n",
    "- Build a ConvNet to identify sign language digits using the TF Keras Functional API\n",
    "\n",
    "**After this assignment you will be able to:**\n",
    "\n",
    "- Build and train a ConvNet in TensorFlow for a __binary__ classification problem\n",
    "- Build and train a ConvNet in TensorFlow for a __multiclass__ classification problem\n",
    "- Explain different use cases for the Sequential and Functional APIs\n",
    "\n",
    "To complete this assignment, you should already be familiar with TensorFlow. If you are not, please refer back to the **TensorFlow Tutorial** of the third week of Course 2 (\"**Improving deep neural networks**\").\n",
    "\n",
    "## Important Note on Submission to the AutoGrader\n",
    "\n",
    "Before submitting your assignment to the AutoGrader, please make sure you are not doing the following:\n",
    "\n",
    "1. You have not added any _extra_ `print` statement(s) in the assignment.\n",
    "2. You have not added any _extra_ code cell(s) in the assignment.\n",
    "3. You have not changed any of the function parameters.\n",
    "4. You are not using any global variables inside your graded exercises. Unless specifically instructed to do so, please refrain from it and use the local variables instead.\n",
    "5. You are not changing the assignment code where it is not required, like creating _extra_ variables.\n",
    "\n",
    "If you do any of the following, you will get something like, `Grader Error: Grader feedback not found` (or similarly unexpected) error upon submitting your assignment. Before asking for help/debugging the errors in your assignment, check for these first. If this is the case, and you don't remember the changes you have made, you can get a fresh copy of the assignment by following these [instructions](https://www.coursera.org/learn/convolutional-neural-networks/supplement/DS4yP/h-ow-to-refresh-your-workspace)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [1 - Packages](#1)\n",
    "    - [1.1 - Load the Data and Split the Data into Train/Test Sets](#1-1)\n",
    "- [2 - Layers in TF Keras](#2)\n",
    "- [3 - The Sequential API](#3)\n",
    "    - [3.1 - Create the Sequential Model](#3-1)\n",
    "        - [Exercise 1 - happyModel](#ex-1)\n",
    "    - [3.2 - Train and Evaluate the Model](#3-2)\n",
    "- [4 - The Functional API](#4)\n",
    "    - [4.1 - Load the SIGNS Dataset](#4-1)\n",
    "    - [4.2 - Split the Data into Train/Test Sets](#4-2)\n",
    "    - [4.3 - Forward Propagation](#4-3)\n",
    "        - [Exercise 2 - convolutional_model](#ex-2)\n",
    "    - [4.4 - Train the Model](#4-4)\n",
    "- [5 - History Object](#5)\n",
    "- [6 - Bibliography](#6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Packages\n",
    "\n",
    "As usual, begin by loading in the packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "### v1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imread\n",
    "import scipy\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfl\n",
    "from tensorflow.python.framework import ops\n",
    "from cnn_utils import *\n",
    "from test_utils import summary, comparator\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1-1'></a>\n",
    "### 1.1 - Load the Data and Split the Data into Train/Test Sets\n",
    "\n",
    "You'll be using the Happy House dataset for this part of the assignment, which contains images of peoples' faces. Your task will be to build a ConvNet that determines whether the people in the images are smiling or not -- because they only get to enter the house if they're smiling!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 600\n",
      "number of test examples = 150\n",
      "X_train shape: (600, 64, 64, 3)\n",
      "Y_train shape: (600, 1)\n",
      "X_test shape: (150, 64, 64, 3)\n",
      "Y_test shape: (150, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_happy_dataset()\n",
    "\n",
    "# Normalize image vectors\n",
    "X_train = X_train_orig/255.\n",
    "X_test = X_test_orig/255.\n",
    "\n",
    "# Reshape\n",
    "Y_train = Y_train_orig.T\n",
    "Y_test = Y_test_orig.T\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can display the images contained in the dataset. Images are **64x64** pixels in RGB format (3 channels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 124\n",
    "plt.imshow(X_train_orig[index]) #display sample training image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2 - Layers in TF Keras \n",
    "\n",
    "In the previous assignment, you created layers manually in numpy. In TF Keras, you don't have to write code directly to create layers. Rather, TF Keras has pre-defined layers you can use. \n",
    "\n",
    "When you create a layer in TF Keras, you are creating a function that takes some input and transforms it into an output you can reuse later. Nice and easy! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3 - The Sequential API\n",
    "\n",
    "In the previous assignment, you built helper functions using `numpy` to understand the mechanics behind convolutional neural networks. Most practical applications of deep learning today are built using programming frameworks, which have many built-in functions you can simply call. Keras is a high-level abstraction built on top of TensorFlow, which allows for even more simplified and optimized model creation and training. \n",
    "\n",
    "For the first part of this assignment, you'll create a model using TF Keras' Sequential API, which allows you to build layer by layer, and is ideal for building models where each layer has **exactly one** input tensor and **one** output tensor. \n",
    "\n",
    "As you'll see, using the Sequential API is simple and straightforward, but is only appropriate for simpler, more straightforward tasks. Later in this notebook you'll spend some time building with a more flexible, powerful alternative: the Functional API. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3-1'></a>\n",
    "### 3.1 - Create the Sequential Model\n",
    "\n",
    "As mentioned earlier, the TensorFlow Keras Sequential API can be used to build simple models with layer operations that proceed in a sequential order. \n",
    "\n",
    "You can also add layers incrementally to a Sequential model with the `.add()` method, or remove them using the `.pop()` method, much like you would in a regular Python list.\n",
    "\n",
    "Actually, you can think of a Sequential model as behaving like a list of layers. Like Python lists, Sequential layers are ordered, and the order in which they are specified matters.  If your model is non-linear or contains layers with multiple inputs or outputs, a Sequential model wouldn't be the right choice!\n",
    "\n",
    "For any layer construction in Keras, you'll need to specify the input shape in advance. This is because in Keras, the shape of the weights is based on the shape of the inputs. The weights are only created when the model first sees some input data. Sequential models can be created by passing a list of layers to the Sequential constructor, like you will do in the next assignment.\n",
    "\n",
    "<a name='ex-1'></a>\n",
    "### Exercise 1 - happyModel\n",
    "\n",
    "Implement the `happyModel` function below to build the following model: `ZEROPAD2D -> CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> FLATTEN -> DENSE`. Take help from [tf.keras.layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers) \n",
    "\n",
    "Also, plug in the following parameters for all the steps:\n",
    "\n",
    " - [ZeroPadding2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/ZeroPadding2D): padding 3, input shape 64 x 64 x 3\n",
    " - [Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D): Use 32 7x7 filters, stride 1\n",
    " - [BatchNormalization](https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization): for axis 3\n",
    " - [ReLU](https://www.tensorflow.org/api_docs/python/tf/keras/layers/ReLU)\n",
    " - [MaxPool2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D): Using default parameters\n",
    " - [Flatten](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten) the previous output.\n",
    " - Fully-connected ([Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)) layer: Apply a fully connected layer with 1 neuron and a sigmoid activation. \n",
    " \n",
    " \n",
    " **Hint:**\n",
    " \n",
    " Use **tfl** as shorthand for **tensorflow.keras.layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "95d28b191f257bdd5b70c7b8952559d5",
     "grade": false,
     "grade_id": "cell-0e56d3fc28b69aec",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: happyModel\n",
    "\n",
    "def happyModel():\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the binary classification model:\n",
    "    ZEROPAD2D -> CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> FLATTEN -> DENSE\n",
    "    \n",
    "    Note that for simplicity and grading purposes, you'll hard-code all the values\n",
    "    such as the stride and kernel (filter) sizes. \n",
    "    Normally, functions should take these values as function parameters.\n",
    "    \n",
    "    Arguments:\n",
    "    None\n",
    "\n",
    "    Returns:\n",
    "    model -- TF Keras model (object containing the information for the entire training process) \n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "            \n",
    "            # YOUR CODE STARTS HERE\n",
    "            \n",
    "            ## ZeroPadding2D with padding 3, input shape of 64 x 64 x 3\n",
    "            tfl.ZeroPadding2D(padding=3, input_shape=(64, 64, 3)),\n",
    "\n",
    "            ## Conv2D with 32 7x7 filters and stride of 1\n",
    "            tfl.Conv2D(filters=32, kernel_size=7, strides=1),\n",
    "            \n",
    "            ## BatchNormalization for axis 3\n",
    "            tfl.BatchNormalization(axis=-1),\n",
    "            \n",
    "            ## ReLU\n",
    "            tfl.ReLU(),\n",
    "\n",
    "            ## Max Pooling 2D with default parameters\n",
    "            tfl.MaxPooling2D(),\n",
    "\n",
    "            ## Flatten layer\n",
    "            tfl.Flatten(),\n",
    "\n",
    "            ## Dense layer with 1 unit for output & 'sigmoid' activation\n",
    "            tfl.Dense(1, activation='sigmoid') \n",
    "\n",
    "            # YOUR CODE ENDS HERE\n",
    "        ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d3575c950e2e78149be2d05d671c80d",
     "grade": true,
     "grade_id": "cell-e3e1046e5c33d775",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/keras/src/layers/reshaping/zero_padding2d.py:72: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ZeroPadding2D', (None, 70, 70, 3), 0, ((3, 3), (3, 3))]\n",
      "['Conv2D', (None, 64, 64, 32), 4736, 'valid', 'linear', 'GlorotUniform']\n",
      "['BatchNormalization', (None, 64, 64, 32), 128]\n",
      "['ReLU', (None, 64, 64, 32), 0]\n",
      "['MaxPooling2D', (None, 32, 32, 32), 0, (2, 2), (2, 2), 'valid']\n",
      "['Flatten', (None, 32768), 0]\n",
      "['Dense', (None, 1), 32769, 'sigmoid']\n",
      "\u001b[32mAll tests passed!\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1729759175.623721   72100 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729759175.624085   72100 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729759175.624394   72100 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729759175.624709   72100 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729759175.665192   72100 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729759175.665595   72100 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729759175.665916   72100 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729759175.666224   72100 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729759175.666529   72100 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729759175.666834   72100 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729759175.667134   72100 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729759175.667434   72100 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729759176.003838   72100 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729759176.004183   72100 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729759176.004492   72100 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729759176.004801   72100 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729759176.005101   72100 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729759176.005394   72100 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729759176.005690   72100 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729759176.005983   72100 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729759176.006275   72100 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729759176.006568   72100 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729759176.006865   72100 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729759176.007156   72100 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729759176.026322   72100 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729759176.026690   72100 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729759176.027014   72100 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729759176.027413   72100 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729759176.027875   72100 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729759176.028176   72100 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729759176.028473   72100 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729759176.028779   72100 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729759176.029082   72100 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-24 10:39:36.029367: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22272 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:02:00.0, compute capability: 8.9\n",
      "I0000 00:00:1729759176.029737   72100 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-24 10:39:36.030014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 21489 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:21:00.0, compute capability: 8.9\n",
      "I0000 00:00:1729759176.030305   72100 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-24 10:39:36.030576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 22272 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:4d:00.0, compute capability: 8.9\n",
      "I0000 00:00:1729759176.030862   72100 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-24 10:39:36.031134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 22272 MB memory:  -> device: 3, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:4e:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "happy_model = happyModel()\n",
    "# Print a summary for each layer\n",
    "for layer in summary(happy_model):\n",
    "    print(layer)\n",
    "    \n",
    "output = [['ZeroPadding2D', (None, 70, 70, 3), 0, ((3, 3), (3, 3))],\n",
    "            ['Conv2D', (None, 64, 64, 32), 4736, 'valid', 'linear', 'GlorotUniform'],\n",
    "            ['BatchNormalization', (None, 64, 64, 32), 128],\n",
    "            ['ReLU', (None, 64, 64, 32), 0],\n",
    "            ['MaxPooling2D', (None, 32, 32, 32), 0, (2, 2), (2, 2), 'valid'],\n",
    "            ['Flatten', (None, 32768), 0],\n",
    "            ['Dense', (None, 1), 32769, 'sigmoid']]\n",
    "    \n",
    "comparator(summary(happy_model), output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Output:\n",
    "\n",
    "```\n",
    "['ZeroPadding2D', (None, 70, 70, 3), 0, ((3, 3), (3, 3))]\n",
    "['Conv2D', (None, 64, 64, 32), 4736, 'valid', 'linear', 'GlorotUniform']\n",
    "['BatchNormalization', (None, 64, 64, 32), 128]\n",
    "['ReLU', (None, 64, 64, 32), 0]\n",
    "['MaxPooling2D', (None, 32, 32, 32), 0, (2, 2), (2, 2), 'valid']\n",
    "['Flatten', (None, 32768), 0]\n",
    "['Dense', (None, 1), 32769, 'sigmoid']\n",
    "All tests passed!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that your model is created, you can compile it for training with an optimizer and loss of your choice. When the string `accuracy` is specified as a metric, the type of accuracy used will be automatically converted based on the loss function used. This is one of the many optimizations built into TensorFlow that make your life easier! If you'd like to read more on how the compiler operates, check the docs [here](https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_model.compile(optimizer='adam',\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to check your model's parameters with the `.summary()` method. This will display the types of layers you have, the shape of the outputs, and how many parameters are in each layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ zero_padding2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,736</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32768</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,769</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ zero_padding2d (\u001b[38;5;33mZeroPadding2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,736\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu (\u001b[38;5;33mReLU\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32768\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │        \u001b[38;5;34m32,769\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">37,633</span> (147.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m37,633\u001b[0m (147.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">37,569</span> (146.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m37,569\u001b[0m (146.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> (256.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m64\u001b[0m (256.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "happy_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3-2'></a>\n",
    "### 3.2 - Train and Evaluate the Model\n",
    "\n",
    "After creating the model, compiling it with your choice of optimizer and loss function, and doing a sanity check on its contents, you are now ready to build! \n",
    "\n",
    "Simply call `.fit()` to train. That's it! No need for mini-batching, saving, or complex backpropagation computations. That's all been done for you, as you're using a TensorFlow dataset with the batches specified already. You do have the option to specify epoch number or minibatch size if you like (for example, in the case of an un-batched dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1729759183.496926   72345 service.cc:146] XLA service 0x7e288c00bbc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1729759183.496966   72345 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "I0000 00:00:1729759183.496971   72345 service.cc:154]   StreamExecutor device (1): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "I0000 00:00:1729759183.496975   72345 service.cc:154]   StreamExecutor device (2): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "I0000 00:00:1729759183.496978   72345 service.cc:154]   StreamExecutor device (3): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2024-10-24 10:39:43.536773: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-24 10:39:43.631687: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 90400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/38\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m59s\u001b[0m 2s/step - accuracy: 0.5000 - loss: 0.7973"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729759184.566329   72345 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.5822 - loss: 2.1396\n",
      "Epoch 2/10\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - accuracy: 0.8617 - loss: 0.4407\n",
      "Epoch 3/10\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9167 - loss: 0.2142 \n",
      "Epoch 4/10\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9723 - loss: 0.0889 \n",
      "Epoch 5/10\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - accuracy: 0.9611 - loss: 0.1089\n",
      "Epoch 6/10\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9069 - loss: 0.2031 \n",
      "Epoch 7/10\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9546 - loss: 0.1240 \n",
      "Epoch 8/10\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.9782 - loss: 0.0820\n",
      "Epoch 9/10\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - accuracy: 0.9692 - loss: 0.0770\n",
      "Epoch 10/10\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - accuracy: 0.9612 - loss: 0.0911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7e2cd264e590>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy_model.fit(X_train, Y_train, epochs=10, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that completes, just use `.evaluate()` to evaluate against your test set. This function will print the value of the loss function and the performance metrics specified during the compilation of the model. In this case, the `binary_crossentropy` and the `accuracy` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.6498 - loss: 1.1450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1895692348480225, 0.6200000047683716]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy_model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easy, right? But what if you need to build a model with shared layers, branches, or multiple inputs and outputs? This is where Sequential, with its beautifully simple yet limited functionality, won't be able to help you. \n",
    "\n",
    "Next up: Enter the Functional API, your slightly more complex, highly flexible friend.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "## 4 - The Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the second half of the assignment, where you'll use Keras' flexible [Functional API](https://www.tensorflow.org/guide/keras/functional) to build a ConvNet that can differentiate between 6 sign language digits. \n",
    "\n",
    "The Functional API can handle models with non-linear topology, shared layers, as well as layers with multiple inputs or outputs. Imagine that, where the Sequential API requires the model to move in a linear fashion through its layers, the Functional API allows much more flexibility. Where Sequential is a straight line, a Functional model is a graph, where the nodes of the layers can connect in many more ways than one. \n",
    "\n",
    "In the visual example below, the one possible direction of the movement Sequential model is shown in contrast to a skip connection, which is just one of the many ways a Functional model can be constructed. A skip connection, as you might have guessed, skips some layer in the network and feeds the output to a later layer in the network. Don't worry, you'll be spending more time with skip connections very soon! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/seq_vs_func.png\" style=\"width:350px;height:200px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4-1'></a>\n",
    "### 4.1 - Load the SIGNS Dataset\n",
    "\n",
    "As a reminder, the SIGNS dataset is a collection of 6 signs representing numbers from 0 to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data (signs)\n",
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_signs_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/SIGNS.png\" style=\"width:800px;height:300px;\">\n",
    "\n",
    "The next cell will show you an example of a labelled image in the dataset. Feel free to change the value of `index` below and re-run to see different examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of an image from the dataset\n",
    "index = 8\n",
    "plt.imshow(X_train_orig[index])\n",
    "print (\"y = \" + str(np.squeeze(Y_train_orig[:, index])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4-2'></a>\n",
    "### 4.2 - Split the Data into Train/Test Sets\n",
    "\n",
    "In Course 2, you built a fully-connected network for this dataset. But since this is an image dataset, it is more natural to apply a ConvNet to it.\n",
    "\n",
    "To get started, let's examine the shapes of your data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 1080\n",
      "number of test examples = 120\n",
      "X_train shape: (1080, 64, 64, 3)\n",
      "Y_train shape: (1080, 6)\n",
      "X_test shape: (120, 64, 64, 3)\n",
      "Y_test shape: (120, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train_orig/255.\n",
    "X_test = X_test_orig/255.\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 6).T\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 6).T\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4-3'></a>\n",
    "### 4.3 - Forward Propagation\n",
    "\n",
    "In TensorFlow, there are built-in functions that implement the convolution steps for you. By now, you should be familiar with how TensorFlow builds computational graphs. In the [Functional API](https://www.tensorflow.org/guide/keras/functional), you create a graph of layers. This is what allows such great flexibility.\n",
    "\n",
    "However, the following model could also be defined using the Sequential API since the information flow is on a single line. But don't deviate. What we want you to learn is to use the functional API.\n",
    "\n",
    "Begin building your graph of layers by creating an input node that functions as a callable object:\n",
    "\n",
    "- **input_img = tf.keras.Input(shape=input_shape):** \n",
    "\n",
    "Then, create a new node in the graph of layers by calling a layer on the `input_img` object: \n",
    "\n",
    "- **tf.keras.layers.Conv2D(filters= ... , kernel_size= ... , padding='same')(input_img):** Read the full documentation on [Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D).\n",
    "\n",
    "- **tf.keras.layers.MaxPool2D(pool_size=(f, f), strides=(s, s), padding='same'):** `MaxPool2D()` downsamples your input using a window of size (f, f) and strides of size (s, s) to carry out max pooling over each window.  For max pooling, you usually operate on a single example at a time and a single channel at a time. Read the full documentation on [MaxPool2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D).\n",
    "\n",
    "- **tf.keras.layers.ReLU():** computes the elementwise ReLU of Z (which can be any shape). You can read the full documentation on [ReLU](https://www.tensorflow.org/api_docs/python/tf/keras/layers/ReLU).\n",
    "\n",
    "- **tf.keras.layers.Flatten()**: given a tensor \"P\", this function takes each training (or test) example in the batch and flattens it into a 1D vector.  \n",
    "\n",
    "    * If a tensor P has the shape (batch_size,h,w,c), it returns a flattened tensor with shape (batch_size, k), where $k=h \\times w \\times c$.  \"k\" equals the product of all the dimension sizes other than the first dimension.\n",
    "    \n",
    "    * For example, given a tensor with dimensions [100, 2, 3, 4], it flattens the tensor to be of shape [100, 24], where 24 = 2 * 3 * 4.  You can read the full documentation on [Flatten](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten).\n",
    "\n",
    "- **tf.keras.layers.Dense(units= ... , activation='softmax')(F):** given the flattened input F, it returns the output computed using a fully connected layer. You can read the full documentation on [Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense).\n",
    "\n",
    "In the last function above (`tf.keras.layers.Dense()`), the fully connected layer automatically initializes weights in the graph and keeps on training them as you train the model. Hence, you did not need to initialize those weights when initializing the parameters.\n",
    "\n",
    "Lastly, before creating the model, you'll need to define the output using the last of the function's compositions (in this example, a Dense layer): \n",
    "\n",
    "- **outputs = tf.keras.layers.Dense(units=6, activation='softmax')(F)**\n",
    "\n",
    "\n",
    "#### Window, kernel, filter, pool\n",
    "\n",
    "The words \"kernel\" and \"filter\" are used to refer to the same thing. The word \"filter\" accounts for the amount of \"kernels\" that will be used in a single convolution layer. \"Pool\" is the name of the operation that takes the max or average value of the kernels. \n",
    "\n",
    "This is why the parameter `pool_size` refers to `kernel_size`, and you use `(f,f)` to refer to the filter size. \n",
    "\n",
    "Pool size and kernel size refer to the same thing in different objects - They refer to the shape of the window where the operation takes place. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-2'></a>\n",
    "### Exercise 2 - convolutional_model\n",
    "\n",
    "Implement the `convolutional_model` function below to build the following model: `CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> DENSE`. Use the functions above! \n",
    "\n",
    "Also, plug in the following parameters for all the steps:\n",
    "\n",
    " - [Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D): Use 8 4 by 4 filters, stride 1, padding is \"SAME\"\n",
    " - [ReLU](https://www.tensorflow.org/api_docs/python/tf/keras/layers/ReLU)\n",
    " - [MaxPool2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D): Use an 8 by 8 filter size and an 8 by 8 stride, padding is \"SAME\"\n",
    " - **Conv2D**: Use 16 2 by 2 filters, stride 1, padding is \"SAME\"\n",
    " - **ReLU**\n",
    " - **MaxPool2D**: Use a 4 by 4 filter size and a 4 by 4 stride, padding is \"SAME\"\n",
    " - [Flatten](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten) the previous output.\n",
    " - Fully-connected ([Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)) layer: Apply a fully connected layer with 6 neurons and a softmax activation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f58643806aa8380c96225fc8b4c5e7aa",
     "grade": false,
     "grade_id": "cell-dac51744a9e03f51",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: convolutional_model\n",
    "\n",
    "def convolutional_model(input_shape):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model:\n",
    "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> DENSE\n",
    "    \n",
    "    Note that for simplicity and grading purposes, you'll hard-code some values\n",
    "    such as the stride and kernel (filter) sizes. \n",
    "    Normally, functions should take these values as function parameters.\n",
    "    \n",
    "    Arguments:\n",
    "    input_img -- input dataset, of shape (input_shape)\n",
    "\n",
    "    Returns:\n",
    "    model -- TF Keras model (object containing the information for the entire training process) \n",
    "    \"\"\"\n",
    "    # YOUR CODE STARTS HERE\n",
    "\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    ## CONV2D: 8 filters 4x4, stride of 1, padding 'SAME'\n",
    "    Z1 = tf.keras.layers.Conv2D(filters=8, kernel_size=4, strides=1, padding='same')(input_img)\n",
    "    \n",
    "    ## RELU\n",
    "    A1 = tf.keras.layers.ReLU()(Z1)\n",
    "    \n",
    "    ## MAXPOOL: window 8x8, stride 8, padding 'SAME'\n",
    "    P1 = tf.keras.layers.MaxPool2D(pool_size=(8, 8), strides=(8, 8), padding='same')(A1)\n",
    "    \n",
    "    ## CONV2D: 16 filters 2x2, stride 1, padding 'SAME'\n",
    "    Z2 = tf.keras.layers.Conv2D(filters=16, kernel_size=2, strides=1, padding='same')(P1)\n",
    "    \n",
    "    ## RELU\n",
    "    A2 = tf.keras.layers.ReLU()(Z2)\n",
    "    \n",
    "    ## MAXPOOL: window 4x4, stride 4, padding 'SAME'\n",
    "    P2 = tf.keras.layers.MaxPool2D(pool_size=(4, 4), strides=(4, 4), padding='same')(A2)\n",
    "    \n",
    "    ## FLATTEN\n",
    "    F  = tf.keras.layers.Flatten()(P2)\n",
    "    \n",
    "    ## Dense layer\n",
    "    ## 6 neurons in output layer. Hint: one of the arguments should be \"activation='softmax'\" \n",
    "    outputs = tf.keras.layers.Dense(units= 6, activation='softmax')(F)\n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    model = tf.keras.Model(inputs=input_img, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "483d626949930a0b0ef20997e7c6ba72",
     "grade": true,
     "grade_id": "cell-45d22e92042174c9",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">392</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │           \u001b[38;5;34m392\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_1 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_2 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m390\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,310</span> (5.12 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,310\u001b[0m (5.12 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,310</span> (5.12 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,310\u001b[0m (5.12 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Layer InputLayer should implement `def compute_output_shape(self, input_shape)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_72100/44648973.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         ['Dense', (None, 6), 390, 'softmax']]\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mcomparator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Coursera/DL/CNN/W1A2/test_utils.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mdescriptors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36mcompute_output_shape\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1089\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m         raise NotImplementedError(\n\u001b[0m\u001b[1;32m   1092\u001b[0m             \u001b[0;34mf\"Layer {self.__class__.__name__} should implement \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m             \u001b[0;34m\"`def compute_output_shape(self, input_shape)`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Layer InputLayer should implement `def compute_output_shape(self, input_shape)`."
     ]
    }
   ],
   "source": [
    "conv_model = convolutional_model((64, 64, 3))\n",
    "conv_model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "conv_model.summary()\n",
    "    \n",
    "output = [['InputLayer', [(None, 64, 64, 3)], 0],\n",
    "        ['Conv2D', (None, 64, 64, 8), 392, 'same', 'linear', 'GlorotUniform'],\n",
    "        ['ReLU', (None, 64, 64, 8), 0],\n",
    "        ['MaxPooling2D', (None, 8, 8, 8), 0, (8, 8), (8, 8), 'same'],\n",
    "        ['Conv2D', (None, 8, 8, 16), 528, 'same', 'linear', 'GlorotUniform'],\n",
    "        ['ReLU', (None, 8, 8, 16), 0],\n",
    "        ['MaxPooling2D', (None, 2, 2, 16), 0, (4, 4), (4, 4), 'same'],\n",
    "        ['Flatten', (None, 64), 0],\n",
    "        ['Dense', (None, 6), 390, 'softmax']]\n",
    "    \n",
    "comparator(summary(conv_model), output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the Sequential and Functional APIs return a TF Keras model object. The only difference is how inputs are handled inside the object model! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4-4'></a>\n",
    "### 4.4 - Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 123ms/step - accuracy: 0.1962 - loss: 1.7930 - val_accuracy: 0.2083 - val_loss: 1.7810\n",
      "Epoch 2/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2244 - loss: 1.7809 - val_accuracy: 0.2083 - val_loss: 1.7757\n",
      "Epoch 3/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2246 - loss: 1.7738 - val_accuracy: 0.2250 - val_loss: 1.7691\n",
      "Epoch 4/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2394 - loss: 1.7661 - val_accuracy: 0.3417 - val_loss: 1.7604\n",
      "Epoch 5/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3075 - loss: 1.7564 - val_accuracy: 0.3833 - val_loss: 1.7504\n",
      "Epoch 6/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3513 - loss: 1.7451 - val_accuracy: 0.4250 - val_loss: 1.7379\n",
      "Epoch 7/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4240 - loss: 1.7316 - val_accuracy: 0.4583 - val_loss: 1.7213\n",
      "Epoch 8/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4455 - loss: 1.7141 - val_accuracy: 0.4750 - val_loss: 1.7027\n",
      "Epoch 9/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4647 - loss: 1.6932 - val_accuracy: 0.4667 - val_loss: 1.6778\n",
      "Epoch 10/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4620 - loss: 1.6663 - val_accuracy: 0.4833 - val_loss: 1.6468\n",
      "Epoch 11/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4686 - loss: 1.6333 - val_accuracy: 0.4750 - val_loss: 1.6114\n",
      "Epoch 12/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4630 - loss: 1.5958 - val_accuracy: 0.4750 - val_loss: 1.5707\n",
      "Epoch 13/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4906 - loss: 1.5507 - val_accuracy: 0.5000 - val_loss: 1.5220\n",
      "Epoch 14/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5007 - loss: 1.4995 - val_accuracy: 0.5000 - val_loss: 1.4728\n",
      "Epoch 15/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5143 - loss: 1.4448 - val_accuracy: 0.5583 - val_loss: 1.4173\n",
      "Epoch 16/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5390 - loss: 1.3823 - val_accuracy: 0.5750 - val_loss: 1.3605\n",
      "Epoch 17/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5612 - loss: 1.3181 - val_accuracy: 0.5750 - val_loss: 1.3115\n",
      "Epoch 18/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5841 - loss: 1.2606 - val_accuracy: 0.5750 - val_loss: 1.2612\n",
      "Epoch 19/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6113 - loss: 1.2066 - val_accuracy: 0.5750 - val_loss: 1.2239\n",
      "Epoch 20/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6224 - loss: 1.1607 - val_accuracy: 0.6167 - val_loss: 1.1869\n",
      "Epoch 21/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6343 - loss: 1.1189 - val_accuracy: 0.6250 - val_loss: 1.1492\n",
      "Epoch 22/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6582 - loss: 1.0825 - val_accuracy: 0.6167 - val_loss: 1.1250\n",
      "Epoch 23/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6629 - loss: 1.0521 - val_accuracy: 0.6583 - val_loss: 1.0912\n",
      "Epoch 24/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6696 - loss: 1.0202 - val_accuracy: 0.6500 - val_loss: 1.0663\n",
      "Epoch 25/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6756 - loss: 0.9945 - val_accuracy: 0.6333 - val_loss: 1.0435\n",
      "Epoch 26/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6842 - loss: 0.9686 - val_accuracy: 0.6417 - val_loss: 1.0188\n",
      "Epoch 27/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6891 - loss: 0.9452 - val_accuracy: 0.6583 - val_loss: 0.9978\n",
      "Epoch 28/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6960 - loss: 0.9237 - val_accuracy: 0.6667 - val_loss: 0.9775\n",
      "Epoch 29/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7080 - loss: 0.9029 - val_accuracy: 0.6833 - val_loss: 0.9559\n",
      "Epoch 30/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7189 - loss: 0.8828 - val_accuracy: 0.6917 - val_loss: 0.9385\n",
      "Epoch 31/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7255 - loss: 0.8652 - val_accuracy: 0.6917 - val_loss: 0.9207\n",
      "Epoch 32/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7318 - loss: 0.8479 - val_accuracy: 0.7000 - val_loss: 0.9049\n",
      "Epoch 33/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7358 - loss: 0.8317 - val_accuracy: 0.6917 - val_loss: 0.8890\n",
      "Epoch 34/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7437 - loss: 0.8162 - val_accuracy: 0.6917 - val_loss: 0.8740\n",
      "Epoch 35/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7479 - loss: 0.8008 - val_accuracy: 0.7083 - val_loss: 0.8592\n",
      "Epoch 36/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7519 - loss: 0.7867 - val_accuracy: 0.7250 - val_loss: 0.8447\n",
      "Epoch 37/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7637 - loss: 0.7726 - val_accuracy: 0.7250 - val_loss: 0.8309\n",
      "Epoch 38/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7650 - loss: 0.7590 - val_accuracy: 0.7417 - val_loss: 0.8178\n",
      "Epoch 39/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7672 - loss: 0.7457 - val_accuracy: 0.7583 - val_loss: 0.8059\n",
      "Epoch 40/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7741 - loss: 0.7328 - val_accuracy: 0.7583 - val_loss: 0.7932\n",
      "Epoch 41/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7787 - loss: 0.7199 - val_accuracy: 0.7583 - val_loss: 0.7818\n",
      "Epoch 42/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7882 - loss: 0.7069 - val_accuracy: 0.7417 - val_loss: 0.7704\n",
      "Epoch 43/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7902 - loss: 0.6940 - val_accuracy: 0.7417 - val_loss: 0.7596\n",
      "Epoch 44/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8041 - loss: 0.6814 - val_accuracy: 0.7500 - val_loss: 0.7490\n",
      "Epoch 45/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8076 - loss: 0.6697 - val_accuracy: 0.7500 - val_loss: 0.7376\n",
      "Epoch 46/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8081 - loss: 0.6576 - val_accuracy: 0.7500 - val_loss: 0.7268\n",
      "Epoch 47/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8107 - loss: 0.6462 - val_accuracy: 0.7500 - val_loss: 0.7159\n",
      "Epoch 48/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8132 - loss: 0.6349 - val_accuracy: 0.7500 - val_loss: 0.7058\n",
      "Epoch 49/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8163 - loss: 0.6245 - val_accuracy: 0.7583 - val_loss: 0.6950\n",
      "Epoch 50/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8229 - loss: 0.6140 - val_accuracy: 0.7667 - val_loss: 0.6849\n",
      "Epoch 51/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8229 - loss: 0.6034 - val_accuracy: 0.7667 - val_loss: 0.6753\n",
      "Epoch 52/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8242 - loss: 0.5933 - val_accuracy: 0.7750 - val_loss: 0.6659\n",
      "Epoch 53/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8303 - loss: 0.5838 - val_accuracy: 0.7833 - val_loss: 0.6564\n",
      "Epoch 54/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8346 - loss: 0.5740 - val_accuracy: 0.7833 - val_loss: 0.6469\n",
      "Epoch 55/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8358 - loss: 0.5648 - val_accuracy: 0.7833 - val_loss: 0.6380\n",
      "Epoch 56/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8358 - loss: 0.5559 - val_accuracy: 0.7833 - val_loss: 0.6289\n",
      "Epoch 57/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8393 - loss: 0.5471 - val_accuracy: 0.7833 - val_loss: 0.6204\n",
      "Epoch 58/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8410 - loss: 0.5385 - val_accuracy: 0.7833 - val_loss: 0.6123\n",
      "Epoch 59/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8431 - loss: 0.5302 - val_accuracy: 0.7833 - val_loss: 0.6044\n",
      "Epoch 60/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8472 - loss: 0.5222 - val_accuracy: 0.7917 - val_loss: 0.5971\n",
      "Epoch 61/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8509 - loss: 0.5145 - val_accuracy: 0.7917 - val_loss: 0.5894\n",
      "Epoch 62/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8553 - loss: 0.5069 - val_accuracy: 0.7917 - val_loss: 0.5828\n",
      "Epoch 63/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8566 - loss: 0.4995 - val_accuracy: 0.7917 - val_loss: 0.5768\n",
      "Epoch 64/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8568 - loss: 0.4924 - val_accuracy: 0.7917 - val_loss: 0.5705\n",
      "Epoch 65/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8621 - loss: 0.4855 - val_accuracy: 0.7917 - val_loss: 0.5644\n",
      "Epoch 66/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8610 - loss: 0.4785 - val_accuracy: 0.7917 - val_loss: 0.5584\n",
      "Epoch 67/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8648 - loss: 0.4718 - val_accuracy: 0.7917 - val_loss: 0.5526\n",
      "Epoch 68/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8666 - loss: 0.4653 - val_accuracy: 0.7917 - val_loss: 0.5466\n",
      "Epoch 69/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8687 - loss: 0.4589 - val_accuracy: 0.7917 - val_loss: 0.5403\n",
      "Epoch 70/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8709 - loss: 0.4527 - val_accuracy: 0.8000 - val_loss: 0.5344\n",
      "Epoch 71/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8709 - loss: 0.4465 - val_accuracy: 0.7917 - val_loss: 0.5283\n",
      "Epoch 72/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8732 - loss: 0.4402 - val_accuracy: 0.7917 - val_loss: 0.5229\n",
      "Epoch 73/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8771 - loss: 0.4345 - val_accuracy: 0.7917 - val_loss: 0.5174\n",
      "Epoch 74/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8764 - loss: 0.4287 - val_accuracy: 0.7917 - val_loss: 0.5120\n",
      "Epoch 75/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8822 - loss: 0.4230 - val_accuracy: 0.8000 - val_loss: 0.5062\n",
      "Epoch 76/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8833 - loss: 0.4174 - val_accuracy: 0.8000 - val_loss: 0.5013\n",
      "Epoch 77/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8837 - loss: 0.4122 - val_accuracy: 0.8083 - val_loss: 0.4963\n",
      "Epoch 78/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8837 - loss: 0.4071 - val_accuracy: 0.8083 - val_loss: 0.4913\n",
      "Epoch 79/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8862 - loss: 0.4019 - val_accuracy: 0.8083 - val_loss: 0.4870\n",
      "Epoch 80/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8868 - loss: 0.3972 - val_accuracy: 0.8167 - val_loss: 0.4822\n",
      "Epoch 81/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8868 - loss: 0.3926 - val_accuracy: 0.8250 - val_loss: 0.4780\n",
      "Epoch 82/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8893 - loss: 0.3880 - val_accuracy: 0.8250 - val_loss: 0.4736\n",
      "Epoch 83/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8881 - loss: 0.3836 - val_accuracy: 0.8250 - val_loss: 0.4695\n",
      "Epoch 84/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8915 - loss: 0.3794 - val_accuracy: 0.8250 - val_loss: 0.4654\n",
      "Epoch 85/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8936 - loss: 0.3751 - val_accuracy: 0.8333 - val_loss: 0.4612\n",
      "Epoch 86/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8980 - loss: 0.3710 - val_accuracy: 0.8417 - val_loss: 0.4574\n",
      "Epoch 87/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9001 - loss: 0.3672 - val_accuracy: 0.8500 - val_loss: 0.4536\n",
      "Epoch 88/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9003 - loss: 0.3633 - val_accuracy: 0.8417 - val_loss: 0.4500\n",
      "Epoch 89/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9005 - loss: 0.3596 - val_accuracy: 0.8417 - val_loss: 0.4460\n",
      "Epoch 90/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9007 - loss: 0.3559 - val_accuracy: 0.8417 - val_loss: 0.4419\n",
      "Epoch 91/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9019 - loss: 0.3524 - val_accuracy: 0.8417 - val_loss: 0.4381\n",
      "Epoch 92/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9019 - loss: 0.3487 - val_accuracy: 0.8417 - val_loss: 0.4349\n",
      "Epoch 93/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9021 - loss: 0.3455 - val_accuracy: 0.8417 - val_loss: 0.4319\n",
      "Epoch 94/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9036 - loss: 0.3422 - val_accuracy: 0.8417 - val_loss: 0.4282\n",
      "Epoch 95/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9043 - loss: 0.3389 - val_accuracy: 0.8417 - val_loss: 0.4256\n",
      "Epoch 96/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9067 - loss: 0.3358 - val_accuracy: 0.8417 - val_loss: 0.4212\n",
      "Epoch 97/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9062 - loss: 0.3325 - val_accuracy: 0.8417 - val_loss: 0.4193\n",
      "Epoch 98/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9084 - loss: 0.3295 - val_accuracy: 0.8417 - val_loss: 0.4158\n",
      "Epoch 99/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9071 - loss: 0.3265 - val_accuracy: 0.8417 - val_loss: 0.4128\n",
      "Epoch 100/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9072 - loss: 0.3236 - val_accuracy: 0.8417 - val_loss: 0.4095\n",
      "Epoch 101/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9088 - loss: 0.3206 - val_accuracy: 0.8417 - val_loss: 0.4069\n",
      "Epoch 102/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9088 - loss: 0.3178 - val_accuracy: 0.8417 - val_loss: 0.4037\n",
      "Epoch 103/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9088 - loss: 0.3148 - val_accuracy: 0.8500 - val_loss: 0.4009\n",
      "Epoch 104/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9095 - loss: 0.3120 - val_accuracy: 0.8417 - val_loss: 0.3983\n",
      "Epoch 105/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9110 - loss: 0.3092 - val_accuracy: 0.8500 - val_loss: 0.3954\n",
      "Epoch 106/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9110 - loss: 0.3064 - val_accuracy: 0.8500 - val_loss: 0.3922\n",
      "Epoch 107/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9110 - loss: 0.3036 - val_accuracy: 0.8583 - val_loss: 0.3897\n",
      "Epoch 108/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9111 - loss: 0.3011 - val_accuracy: 0.8583 - val_loss: 0.3870\n",
      "Epoch 109/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9111 - loss: 0.2985 - val_accuracy: 0.8667 - val_loss: 0.3843\n",
      "Epoch 110/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9126 - loss: 0.2961 - val_accuracy: 0.8583 - val_loss: 0.3816\n",
      "Epoch 111/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9147 - loss: 0.2935 - val_accuracy: 0.8667 - val_loss: 0.3792\n",
      "Epoch 112/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9147 - loss: 0.2910 - val_accuracy: 0.8667 - val_loss: 0.3768\n",
      "Epoch 113/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9147 - loss: 0.2886 - val_accuracy: 0.8667 - val_loss: 0.3742\n",
      "Epoch 114/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9156 - loss: 0.2862 - val_accuracy: 0.8667 - val_loss: 0.3725\n",
      "Epoch 115/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9156 - loss: 0.2838 - val_accuracy: 0.8667 - val_loss: 0.3695\n",
      "Epoch 116/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9157 - loss: 0.2814 - val_accuracy: 0.8667 - val_loss: 0.3672\n",
      "Epoch 117/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9162 - loss: 0.2791 - val_accuracy: 0.8667 - val_loss: 0.3647\n",
      "Epoch 118/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9157 - loss: 0.2768 - val_accuracy: 0.8750 - val_loss: 0.3628\n",
      "Epoch 119/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9157 - loss: 0.2747 - val_accuracy: 0.8667 - val_loss: 0.3605\n",
      "Epoch 120/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9157 - loss: 0.2725 - val_accuracy: 0.8750 - val_loss: 0.3584\n",
      "Epoch 121/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9183 - loss: 0.2703 - val_accuracy: 0.8750 - val_loss: 0.3565\n",
      "Epoch 122/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9186 - loss: 0.2682 - val_accuracy: 0.8833 - val_loss: 0.3540\n",
      "Epoch 123/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9201 - loss: 0.2663 - val_accuracy: 0.8833 - val_loss: 0.3528\n",
      "Epoch 124/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9212 - loss: 0.2642 - val_accuracy: 0.8833 - val_loss: 0.3497\n",
      "Epoch 125/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9206 - loss: 0.2624 - val_accuracy: 0.8833 - val_loss: 0.3478\n",
      "Epoch 126/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9212 - loss: 0.2603 - val_accuracy: 0.8833 - val_loss: 0.3458\n",
      "Epoch 127/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9218 - loss: 0.2585 - val_accuracy: 0.8833 - val_loss: 0.3434\n",
      "Epoch 128/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9213 - loss: 0.2566 - val_accuracy: 0.8833 - val_loss: 0.3417\n",
      "Epoch 129/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9259 - loss: 0.2549 - val_accuracy: 0.8833 - val_loss: 0.3389\n",
      "Epoch 130/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9245 - loss: 0.2531 - val_accuracy: 0.8917 - val_loss: 0.3377\n",
      "Epoch 131/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9280 - loss: 0.2512 - val_accuracy: 0.8917 - val_loss: 0.3351\n",
      "Epoch 132/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9295 - loss: 0.2494 - val_accuracy: 0.8917 - val_loss: 0.3338\n",
      "Epoch 133/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9300 - loss: 0.2475 - val_accuracy: 0.8917 - val_loss: 0.3317\n",
      "Epoch 134/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9303 - loss: 0.2459 - val_accuracy: 0.8917 - val_loss: 0.3303\n",
      "Epoch 135/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9317 - loss: 0.2440 - val_accuracy: 0.8917 - val_loss: 0.3283\n",
      "Epoch 136/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9306 - loss: 0.2423 - val_accuracy: 0.8917 - val_loss: 0.3265\n",
      "Epoch 137/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9317 - loss: 0.2406 - val_accuracy: 0.8917 - val_loss: 0.3250\n",
      "Epoch 138/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9328 - loss: 0.2390 - val_accuracy: 0.8917 - val_loss: 0.3228\n",
      "Epoch 139/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9328 - loss: 0.2375 - val_accuracy: 0.8917 - val_loss: 0.3218\n",
      "Epoch 140/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9338 - loss: 0.2358 - val_accuracy: 0.8917 - val_loss: 0.3196\n",
      "Epoch 141/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9340 - loss: 0.2343 - val_accuracy: 0.8917 - val_loss: 0.3178\n",
      "Epoch 142/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9358 - loss: 0.2327 - val_accuracy: 0.8917 - val_loss: 0.3165\n",
      "Epoch 143/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9368 - loss: 0.2311 - val_accuracy: 0.8917 - val_loss: 0.3150\n",
      "Epoch 144/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9371 - loss: 0.2297 - val_accuracy: 0.8917 - val_loss: 0.3133\n",
      "Epoch 145/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9395 - loss: 0.2282 - val_accuracy: 0.8917 - val_loss: 0.3118\n",
      "Epoch 146/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9380 - loss: 0.2267 - val_accuracy: 0.8917 - val_loss: 0.3105\n",
      "Epoch 147/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9400 - loss: 0.2252 - val_accuracy: 0.8917 - val_loss: 0.3082\n",
      "Epoch 148/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9385 - loss: 0.2239 - val_accuracy: 0.8917 - val_loss: 0.3071\n",
      "Epoch 149/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9389 - loss: 0.2224 - val_accuracy: 0.8917 - val_loss: 0.3056\n",
      "Epoch 150/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9395 - loss: 0.2212 - val_accuracy: 0.8917 - val_loss: 0.3042\n",
      "Epoch 151/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9406 - loss: 0.2195 - val_accuracy: 0.8917 - val_loss: 0.3032\n",
      "Epoch 152/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9422 - loss: 0.2182 - val_accuracy: 0.8917 - val_loss: 0.3014\n",
      "Epoch 153/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9406 - loss: 0.2168 - val_accuracy: 0.8917 - val_loss: 0.3006\n",
      "Epoch 154/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9424 - loss: 0.2154 - val_accuracy: 0.8917 - val_loss: 0.2986\n",
      "Epoch 155/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9420 - loss: 0.2142 - val_accuracy: 0.8917 - val_loss: 0.2977\n",
      "Epoch 156/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9431 - loss: 0.2130 - val_accuracy: 0.8917 - val_loss: 0.2965\n",
      "Epoch 157/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9434 - loss: 0.2116 - val_accuracy: 0.9000 - val_loss: 0.2951\n",
      "Epoch 158/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9434 - loss: 0.2104 - val_accuracy: 0.9000 - val_loss: 0.2939\n",
      "Epoch 159/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9434 - loss: 0.2090 - val_accuracy: 0.9000 - val_loss: 0.2923\n",
      "Epoch 160/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9431 - loss: 0.2078 - val_accuracy: 0.9000 - val_loss: 0.2909\n",
      "Epoch 161/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9436 - loss: 0.2066 - val_accuracy: 0.9000 - val_loss: 0.2901\n",
      "Epoch 162/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9441 - loss: 0.2052 - val_accuracy: 0.9000 - val_loss: 0.2886\n",
      "Epoch 163/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9447 - loss: 0.2041 - val_accuracy: 0.9000 - val_loss: 0.2877\n",
      "Epoch 164/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9447 - loss: 0.2029 - val_accuracy: 0.9000 - val_loss: 0.2864\n",
      "Epoch 165/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9444 - loss: 0.2015 - val_accuracy: 0.9000 - val_loss: 0.2853\n",
      "Epoch 166/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9455 - loss: 0.2006 - val_accuracy: 0.9000 - val_loss: 0.2842\n",
      "Epoch 167/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9474 - loss: 0.1993 - val_accuracy: 0.9000 - val_loss: 0.2831\n",
      "Epoch 168/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9454 - loss: 0.1982 - val_accuracy: 0.9000 - val_loss: 0.2818\n",
      "Epoch 169/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9472 - loss: 0.1971 - val_accuracy: 0.9000 - val_loss: 0.2808\n",
      "Epoch 170/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9477 - loss: 0.1961 - val_accuracy: 0.9000 - val_loss: 0.2801\n",
      "Epoch 171/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9472 - loss: 0.1951 - val_accuracy: 0.9000 - val_loss: 0.2786\n",
      "Epoch 172/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9477 - loss: 0.1939 - val_accuracy: 0.9000 - val_loss: 0.2777\n",
      "Epoch 173/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9474 - loss: 0.1928 - val_accuracy: 0.9000 - val_loss: 0.2766\n",
      "Epoch 174/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9480 - loss: 0.1916 - val_accuracy: 0.9000 - val_loss: 0.2754\n",
      "Epoch 175/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9484 - loss: 0.1906 - val_accuracy: 0.9000 - val_loss: 0.2745\n",
      "Epoch 176/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9484 - loss: 0.1897 - val_accuracy: 0.9000 - val_loss: 0.2736\n",
      "Epoch 177/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9484 - loss: 0.1885 - val_accuracy: 0.9000 - val_loss: 0.2730\n",
      "Epoch 178/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9484 - loss: 0.1877 - val_accuracy: 0.8917 - val_loss: 0.2725\n",
      "Epoch 179/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9484 - loss: 0.1863 - val_accuracy: 0.8917 - val_loss: 0.2715\n",
      "Epoch 180/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9462 - loss: 0.1855 - val_accuracy: 0.8917 - val_loss: 0.2707\n",
      "Epoch 181/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9462 - loss: 0.1845 - val_accuracy: 0.8917 - val_loss: 0.2699\n",
      "Epoch 182/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9462 - loss: 0.1836 - val_accuracy: 0.8917 - val_loss: 0.2692\n",
      "Epoch 183/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9462 - loss: 0.1826 - val_accuracy: 0.8917 - val_loss: 0.2684\n",
      "Epoch 184/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9486 - loss: 0.1817 - val_accuracy: 0.8917 - val_loss: 0.2671\n",
      "Epoch 185/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9486 - loss: 0.1806 - val_accuracy: 0.8917 - val_loss: 0.2669\n",
      "Epoch 186/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9486 - loss: 0.1798 - val_accuracy: 0.8917 - val_loss: 0.2659\n",
      "Epoch 187/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9486 - loss: 0.1786 - val_accuracy: 0.8917 - val_loss: 0.2645\n",
      "Epoch 188/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9486 - loss: 0.1779 - val_accuracy: 0.8917 - val_loss: 0.2643\n",
      "Epoch 189/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9486 - loss: 0.1768 - val_accuracy: 0.9000 - val_loss: 0.2634\n",
      "Epoch 190/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9517 - loss: 0.1761 - val_accuracy: 0.9000 - val_loss: 0.2624\n",
      "Epoch 191/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9517 - loss: 0.1751 - val_accuracy: 0.9000 - val_loss: 0.2616\n",
      "Epoch 192/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9529 - loss: 0.1743 - val_accuracy: 0.9000 - val_loss: 0.2609\n",
      "Epoch 193/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9529 - loss: 0.1734 - val_accuracy: 0.9000 - val_loss: 0.2604\n",
      "Epoch 194/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9551 - loss: 0.1726 - val_accuracy: 0.9000 - val_loss: 0.2601\n",
      "Epoch 195/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9529 - loss: 0.1717 - val_accuracy: 0.9000 - val_loss: 0.2592\n",
      "Epoch 196/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9560 - loss: 0.1708 - val_accuracy: 0.9000 - val_loss: 0.2584\n",
      "Epoch 197/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9570 - loss: 0.1701 - val_accuracy: 0.9000 - val_loss: 0.2585\n",
      "Epoch 198/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9565 - loss: 0.1690 - val_accuracy: 0.9000 - val_loss: 0.2574\n",
      "Epoch 199/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9588 - loss: 0.1684 - val_accuracy: 0.9000 - val_loss: 0.2575\n",
      "Epoch 200/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9592 - loss: 0.1676 - val_accuracy: 0.9000 - val_loss: 0.2563\n",
      "Epoch 201/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9598 - loss: 0.1668 - val_accuracy: 0.9000 - val_loss: 0.2568\n",
      "Epoch 202/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9593 - loss: 0.1661 - val_accuracy: 0.9000 - val_loss: 0.2546\n",
      "Epoch 203/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9598 - loss: 0.1654 - val_accuracy: 0.9000 - val_loss: 0.2560\n",
      "Epoch 204/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9601 - loss: 0.1643 - val_accuracy: 0.9000 - val_loss: 0.2536\n",
      "Epoch 205/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9613 - loss: 0.1639 - val_accuracy: 0.9000 - val_loss: 0.2552\n",
      "Epoch 206/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.1629 - val_accuracy: 0.9000 - val_loss: 0.2533\n",
      "Epoch 207/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.1624 - val_accuracy: 0.9000 - val_loss: 0.2541\n",
      "Epoch 208/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9601 - loss: 0.1617 - val_accuracy: 0.9000 - val_loss: 0.2528\n",
      "Epoch 209/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9601 - loss: 0.1611 - val_accuracy: 0.9000 - val_loss: 0.2532\n",
      "Epoch 210/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9601 - loss: 0.1604 - val_accuracy: 0.9000 - val_loss: 0.2525\n",
      "Epoch 211/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9613 - loss: 0.1597 - val_accuracy: 0.9000 - val_loss: 0.2513\n",
      "Epoch 212/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9613 - loss: 0.1590 - val_accuracy: 0.9000 - val_loss: 0.2537\n",
      "Epoch 213/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9613 - loss: 0.1580 - val_accuracy: 0.9000 - val_loss: 0.2523\n",
      "Epoch 214/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9616 - loss: 0.1577 - val_accuracy: 0.9000 - val_loss: 0.2524\n",
      "Epoch 215/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9603 - loss: 0.1569 - val_accuracy: 0.9000 - val_loss: 0.2527\n",
      "Epoch 216/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9597 - loss: 0.1563 - val_accuracy: 0.9000 - val_loss: 0.2513\n",
      "Epoch 217/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9603 - loss: 0.1559 - val_accuracy: 0.9000 - val_loss: 0.2529\n",
      "Epoch 218/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9610 - loss: 0.1550 - val_accuracy: 0.9000 - val_loss: 0.2513\n",
      "Epoch 219/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9616 - loss: 0.1543 - val_accuracy: 0.9000 - val_loss: 0.2525\n",
      "Epoch 220/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9610 - loss: 0.1538 - val_accuracy: 0.9000 - val_loss: 0.2525\n",
      "Epoch 221/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9610 - loss: 0.1531 - val_accuracy: 0.9083 - val_loss: 0.2527\n",
      "Epoch 222/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9615 - loss: 0.1526 - val_accuracy: 0.8917 - val_loss: 0.2522\n",
      "Epoch 223/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9615 - loss: 0.1518 - val_accuracy: 0.9083 - val_loss: 0.2520\n",
      "Epoch 224/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9626 - loss: 0.1514 - val_accuracy: 0.8917 - val_loss: 0.2516\n",
      "Epoch 225/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9620 - loss: 0.1506 - val_accuracy: 0.9000 - val_loss: 0.2544\n",
      "Epoch 226/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9626 - loss: 0.1499 - val_accuracy: 0.9000 - val_loss: 0.2515\n",
      "Epoch 227/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9629 - loss: 0.1492 - val_accuracy: 0.9000 - val_loss: 0.2538\n",
      "Epoch 228/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9615 - loss: 0.1484 - val_accuracy: 0.9000 - val_loss: 0.2534\n",
      "Epoch 229/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9617 - loss: 0.1479 - val_accuracy: 0.9083 - val_loss: 0.2525\n",
      "Epoch 230/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9615 - loss: 0.1476 - val_accuracy: 0.9083 - val_loss: 0.2512\n",
      "Epoch 231/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9607 - loss: 0.1468 - val_accuracy: 0.9083 - val_loss: 0.2530\n",
      "Epoch 232/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9592 - loss: 0.1467 - val_accuracy: 0.9083 - val_loss: 0.2529\n",
      "Epoch 233/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9596 - loss: 0.1461 - val_accuracy: 0.9083 - val_loss: 0.2541\n",
      "Epoch 234/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9597 - loss: 0.1455 - val_accuracy: 0.9083 - val_loss: 0.2529\n",
      "Epoch 235/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9604 - loss: 0.1452 - val_accuracy: 0.9083 - val_loss: 0.2526\n",
      "Epoch 236/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9604 - loss: 0.1448 - val_accuracy: 0.9083 - val_loss: 0.2547\n",
      "Epoch 237/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9609 - loss: 0.1441 - val_accuracy: 0.9083 - val_loss: 0.2529\n",
      "Epoch 238/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9631 - loss: 0.1437 - val_accuracy: 0.9083 - val_loss: 0.2535\n",
      "Epoch 239/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9609 - loss: 0.1433 - val_accuracy: 0.9083 - val_loss: 0.2535\n",
      "Epoch 240/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9614 - loss: 0.1426 - val_accuracy: 0.9083 - val_loss: 0.2526\n",
      "Epoch 241/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.1418 - val_accuracy: 0.9083 - val_loss: 0.2543\n",
      "Epoch 242/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.1418 - val_accuracy: 0.9083 - val_loss: 0.2546\n",
      "Epoch 243/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9628 - loss: 0.1414 - val_accuracy: 0.9083 - val_loss: 0.2548\n",
      "Epoch 244/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9629 - loss: 0.1409 - val_accuracy: 0.9083 - val_loss: 0.2539\n",
      "Epoch 245/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.1405 - val_accuracy: 0.9083 - val_loss: 0.2542\n",
      "Epoch 246/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9628 - loss: 0.1400 - val_accuracy: 0.9083 - val_loss: 0.2537\n",
      "Epoch 247/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.1392 - val_accuracy: 0.9083 - val_loss: 0.2540\n",
      "Epoch 248/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.1388 - val_accuracy: 0.9083 - val_loss: 0.2537\n",
      "Epoch 249/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9626 - loss: 0.1384 - val_accuracy: 0.9083 - val_loss: 0.2538\n",
      "Epoch 250/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9626 - loss: 0.1378 - val_accuracy: 0.9083 - val_loss: 0.2544\n",
      "Epoch 251/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9634 - loss: 0.1379 - val_accuracy: 0.9083 - val_loss: 0.2542\n",
      "Epoch 252/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9622 - loss: 0.1374 - val_accuracy: 0.9083 - val_loss: 0.2552\n",
      "Epoch 253/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9625 - loss: 0.1369 - val_accuracy: 0.9083 - val_loss: 0.2537\n",
      "Epoch 254/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9593 - loss: 0.1363 - val_accuracy: 0.9083 - val_loss: 0.2538\n",
      "Epoch 255/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9671 - loss: 0.1360 - val_accuracy: 0.9083 - val_loss: 0.2539\n",
      "Epoch 256/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9616 - loss: 0.1363 - val_accuracy: 0.9083 - val_loss: 0.2541\n",
      "Epoch 257/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9635 - loss: 0.1357 - val_accuracy: 0.9083 - val_loss: 0.2535\n",
      "Epoch 258/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9601 - loss: 0.1354 - val_accuracy: 0.9083 - val_loss: 0.2537\n",
      "Epoch 259/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9594 - loss: 0.1345 - val_accuracy: 0.9083 - val_loss: 0.2519\n",
      "Epoch 260/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9588 - loss: 0.1345 - val_accuracy: 0.9083 - val_loss: 0.2523\n",
      "Epoch 261/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9600 - loss: 0.1336 - val_accuracy: 0.9167 - val_loss: 0.2522\n",
      "Epoch 262/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9586 - loss: 0.1337 - val_accuracy: 0.9167 - val_loss: 0.2521\n",
      "Epoch 263/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9581 - loss: 0.1335 - val_accuracy: 0.9167 - val_loss: 0.2523\n",
      "Epoch 264/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9579 - loss: 0.1333 - val_accuracy: 0.9167 - val_loss: 0.2530\n",
      "Epoch 265/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9573 - loss: 0.1332 - val_accuracy: 0.9167 - val_loss: 0.2564\n",
      "Epoch 266/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9589 - loss: 0.1334 - val_accuracy: 0.9083 - val_loss: 0.2609\n",
      "Epoch 267/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9605 - loss: 0.1336 - val_accuracy: 0.8917 - val_loss: 0.2714\n",
      "Epoch 268/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9612 - loss: 0.1354 - val_accuracy: 0.8833 - val_loss: 0.2735\n",
      "Epoch 269/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9630 - loss: 0.1362 - val_accuracy: 0.8917 - val_loss: 0.2786\n",
      "Epoch 270/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9620 - loss: 0.1369 - val_accuracy: 0.8917 - val_loss: 0.2811\n",
      "Epoch 271/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9624 - loss: 0.1373 - val_accuracy: 0.8833 - val_loss: 0.2792\n",
      "Epoch 272/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9569 - loss: 0.1372 - val_accuracy: 0.8917 - val_loss: 0.2848\n",
      "Epoch 273/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9587 - loss: 0.1374 - val_accuracy: 0.9000 - val_loss: 0.2846\n",
      "Epoch 274/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.1379 - val_accuracy: 0.8917 - val_loss: 0.2842\n",
      "Epoch 275/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9576 - loss: 0.1367 - val_accuracy: 0.9000 - val_loss: 0.2806\n",
      "Epoch 276/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9598 - loss: 0.1353 - val_accuracy: 0.9000 - val_loss: 0.2783\n",
      "Epoch 277/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9563 - loss: 0.1338 - val_accuracy: 0.9000 - val_loss: 0.2764\n",
      "Epoch 278/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9598 - loss: 0.1323 - val_accuracy: 0.9083 - val_loss: 0.2732\n",
      "Epoch 279/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9602 - loss: 0.1302 - val_accuracy: 0.9083 - val_loss: 0.2716\n",
      "Epoch 280/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9598 - loss: 0.1289 - val_accuracy: 0.9083 - val_loss: 0.2710\n",
      "Epoch 281/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9623 - loss: 0.1278 - val_accuracy: 0.9083 - val_loss: 0.2687\n",
      "Epoch 282/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9612 - loss: 0.1267 - val_accuracy: 0.9083 - val_loss: 0.2681\n",
      "Epoch 283/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9623 - loss: 0.1253 - val_accuracy: 0.9083 - val_loss: 0.2660\n",
      "Epoch 284/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9637 - loss: 0.1243 - val_accuracy: 0.9083 - val_loss: 0.2661\n",
      "Epoch 285/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9642 - loss: 0.1232 - val_accuracy: 0.9083 - val_loss: 0.2644\n",
      "Epoch 286/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9657 - loss: 0.1219 - val_accuracy: 0.9083 - val_loss: 0.2637\n",
      "Epoch 287/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9659 - loss: 0.1204 - val_accuracy: 0.9083 - val_loss: 0.2644\n",
      "Epoch 288/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9670 - loss: 0.1193 - val_accuracy: 0.9083 - val_loss: 0.2647\n",
      "Epoch 289/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9677 - loss: 0.1183 - val_accuracy: 0.9083 - val_loss: 0.2642\n",
      "Epoch 290/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9677 - loss: 0.1172 - val_accuracy: 0.9167 - val_loss: 0.2659\n",
      "Epoch 291/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9682 - loss: 0.1162 - val_accuracy: 0.9167 - val_loss: 0.2655\n",
      "Epoch 292/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9677 - loss: 0.1156 - val_accuracy: 0.9167 - val_loss: 0.2687\n",
      "Epoch 293/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9698 - loss: 0.1155 - val_accuracy: 0.9167 - val_loss: 0.2699\n",
      "Epoch 294/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9708 - loss: 0.1150 - val_accuracy: 0.9167 - val_loss: 0.2690\n",
      "Epoch 295/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9703 - loss: 0.1143 - val_accuracy: 0.9167 - val_loss: 0.2706\n",
      "Epoch 296/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9716 - loss: 0.1133 - val_accuracy: 0.9167 - val_loss: 0.2674\n",
      "Epoch 297/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9685 - loss: 0.1123 - val_accuracy: 0.9167 - val_loss: 0.2704\n",
      "Epoch 298/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9721 - loss: 0.1114 - val_accuracy: 0.9167 - val_loss: 0.2683\n",
      "Epoch 299/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9725 - loss: 0.1107 - val_accuracy: 0.9167 - val_loss: 0.2689\n",
      "Epoch 300/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9714 - loss: 0.1104 - val_accuracy: 0.9167 - val_loss: 0.2705\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train)).batch(64)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test)).batch(64)\n",
    "history = conv_model.fit(train_dataset, epochs=300, validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='5'></a>\n",
    "## 5 - History Object \n",
    "\n",
    "The history object is an output of the `.fit()` operation, and provides a record of all the loss and metric values in memory. It's stored as a dictionary that you can retrieve at `history.history`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': [0.19629628956317902,\n",
       "  0.2222222238779068,\n",
       "  0.2212962955236435,\n",
       "  0.2361111044883728,\n",
       "  0.30092594027519226,\n",
       "  0.32870370149612427,\n",
       "  0.39351850748062134,\n",
       "  0.4175925850868225,\n",
       "  0.4342592656612396,\n",
       "  0.43703705072402954,\n",
       "  0.45185184478759766,\n",
       "  0.4546296298503876,\n",
       "  0.4749999940395355,\n",
       "  0.49351853132247925,\n",
       "  0.5055555701255798,\n",
       "  0.5314815044403076,\n",
       "  0.5574073791503906,\n",
       "  0.5777778029441833,\n",
       "  0.604629635810852,\n",
       "  0.6138888597488403,\n",
       "  0.6296296119689941,\n",
       "  0.6481481194496155,\n",
       "  0.6583333611488342,\n",
       "  0.664814829826355,\n",
       "  0.6722221970558167,\n",
       "  0.6796296238899231,\n",
       "  0.6898148059844971,\n",
       "  0.6962962746620178,\n",
       "  0.7083333134651184,\n",
       "  0.7175925970077515,\n",
       "  0.7259259223937988,\n",
       "  0.730555534362793,\n",
       "  0.7370370626449585,\n",
       "  0.7425925731658936,\n",
       "  0.7509258985519409,\n",
       "  0.7546296119689941,\n",
       "  0.7675926089286804,\n",
       "  0.7722222208976746,\n",
       "  0.7749999761581421,\n",
       "  0.7824074029922485,\n",
       "  0.7888888716697693,\n",
       "  0.7953703999519348,\n",
       "  0.8009259104728699,\n",
       "  0.8046296238899231,\n",
       "  0.8092592358589172,\n",
       "  0.8101851940155029,\n",
       "  0.8101851940155029,\n",
       "  0.8175926208496094,\n",
       "  0.8212962746620178,\n",
       "  0.8268518447875977,\n",
       "  0.8268518447875977,\n",
       "  0.8277778029441833,\n",
       "  0.8296296000480652,\n",
       "  0.8342592716217041,\n",
       "  0.8370370268821716,\n",
       "  0.8370370268821716,\n",
       "  0.8398148417472839,\n",
       "  0.8416666388511658,\n",
       "  0.8435184955596924,\n",
       "  0.8462963104248047,\n",
       "  0.8490740656852722,\n",
       "  0.8527777791023254,\n",
       "  0.854629635810852,\n",
       "  0.855555534362793,\n",
       "  0.8592592477798462,\n",
       "  0.8574073910713196,\n",
       "  0.8601852059364319,\n",
       "  0.8611111044883728,\n",
       "  0.8638888597488403,\n",
       "  0.8675925731658936,\n",
       "  0.8675925731658936,\n",
       "  0.8703703880310059,\n",
       "  0.8731481432914734,\n",
       "  0.8731481432914734,\n",
       "  0.8768518567085266,\n",
       "  0.8796296119689941,\n",
       "  0.8796296119689941,\n",
       "  0.8796296119689941,\n",
       "  0.8814814686775208,\n",
       "  0.8824074268341064,\n",
       "  0.8824074268341064,\n",
       "  0.8842592835426331,\n",
       "  0.8833333253860474,\n",
       "  0.885185182094574,\n",
       "  0.8879629373550415,\n",
       "  0.8916666507720947,\n",
       "  0.8925926089286804,\n",
       "  0.8935185074806213,\n",
       "  0.894444465637207,\n",
       "  0.895370364189148,\n",
       "  0.8962963223457336,\n",
       "  0.8962963223457336,\n",
       "  0.8972222208976746,\n",
       "  0.8981481194496155,\n",
       "  0.8990740776062012,\n",
       "  0.9009259343147278,\n",
       "  0.9009259343147278,\n",
       "  0.9027777910232544,\n",
       "  0.9027777910232544,\n",
       "  0.9037036895751953,\n",
       "  0.9055555462837219,\n",
       "  0.9055555462837219,\n",
       "  0.9055555462837219,\n",
       "  0.9064815044403076,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9092592597007751,\n",
       "  0.9092592597007751,\n",
       "  0.9101851582527161,\n",
       "  0.9111111164093018,\n",
       "  0.9111111164093018,\n",
       "  0.9111111164093018,\n",
       "  0.9120370149612427,\n",
       "  0.9120370149612427,\n",
       "  0.9120370149612427,\n",
       "  0.9129629731178284,\n",
       "  0.9120370149612427,\n",
       "  0.9120370149612427,\n",
       "  0.9120370149612427,\n",
       "  0.9120370149612427,\n",
       "  0.9129629731178284,\n",
       "  0.9138888716697693,\n",
       "  0.9157407283782959,\n",
       "  0.914814829826355,\n",
       "  0.9157407283782959,\n",
       "  0.9166666865348816,\n",
       "  0.9157407283782959,\n",
       "  0.9203703999519348,\n",
       "  0.9185185432434082,\n",
       "  0.9212962985038757,\n",
       "  0.9222221970558167,\n",
       "  0.9231481552124023,\n",
       "  0.9240740537643433,\n",
       "  0.925000011920929,\n",
       "  0.925000011920929,\n",
       "  0.925000011920929,\n",
       "  0.9268518686294556,\n",
       "  0.9268518686294556,\n",
       "  0.9268518686294556,\n",
       "  0.9277777671813965,\n",
       "  0.9296296238899231,\n",
       "  0.9314814805984497,\n",
       "  0.9314814805984497,\n",
       "  0.9333333373069763,\n",
       "  0.9324073791503906,\n",
       "  0.9351851940155029,\n",
       "  0.9333333373069763,\n",
       "  0.9342592358589172,\n",
       "  0.9351851940155029,\n",
       "  0.9361110925674438,\n",
       "  0.9370370507240295,\n",
       "  0.9361110925674438,\n",
       "  0.9379629492759705,\n",
       "  0.9379629492759705,\n",
       "  0.9379629492759705,\n",
       "  0.9388889074325562,\n",
       "  0.9388889074325562,\n",
       "  0.9388889074325562,\n",
       "  0.9379629492759705,\n",
       "  0.9398148059844971,\n",
       "  0.9398148059844971,\n",
       "  0.9416666626930237,\n",
       "  0.9416666626930237,\n",
       "  0.9407407641410828,\n",
       "  0.9435185194015503,\n",
       "  0.9435185194015503,\n",
       "  0.9425926208496094,\n",
       "  0.9425926208496094,\n",
       "  0.9444444179534912,\n",
       "  0.9425926208496094,\n",
       "  0.9444444179534912,\n",
       "  0.9435185194015503,\n",
       "  0.9444444179534912,\n",
       "  0.9453703761100769,\n",
       "  0.9453703761100769,\n",
       "  0.9453703761100769,\n",
       "  0.9453703761100769,\n",
       "  0.9453703761100769,\n",
       "  0.9444444179534912,\n",
       "  0.9444444179534912,\n",
       "  0.9444444179534912,\n",
       "  0.9444444179534912,\n",
       "  0.9462962746620178,\n",
       "  0.9462962746620178,\n",
       "  0.9462962746620178,\n",
       "  0.9462962746620178,\n",
       "  0.9462962746620178,\n",
       "  0.9462962746620178,\n",
       "  0.9472222328186035,\n",
       "  0.9472222328186035,\n",
       "  0.9481481313705444,\n",
       "  0.9481481313705444,\n",
       "  0.9490740895271301,\n",
       "  0.9481481313705444,\n",
       "  0.949999988079071,\n",
       "  0.9509259462356567,\n",
       "  0.9509259462356567,\n",
       "  0.9518518447875977,\n",
       "  0.9527778029441833,\n",
       "  0.9537037014961243,\n",
       "  0.9527778029441833,\n",
       "  0.9537037014961243,\n",
       "  0.9546296000480652,\n",
       "  0.9555555582046509,\n",
       "  0.9546296000480652,\n",
       "  0.9546296000480652,\n",
       "  0.9546296000480652,\n",
       "  0.9546296000480652,\n",
       "  0.9546296000480652,\n",
       "  0.9555555582046509,\n",
       "  0.9555555582046509,\n",
       "  0.9555555582046509,\n",
       "  0.9564814567565918,\n",
       "  0.9555555582046509,\n",
       "  0.9546296000480652,\n",
       "  0.9555555582046509,\n",
       "  0.9555555582046509,\n",
       "  0.9564814567565918,\n",
       "  0.9555555582046509,\n",
       "  0.9555555582046509,\n",
       "  0.9564814567565918,\n",
       "  0.9564814567565918,\n",
       "  0.9574074149131775,\n",
       "  0.9574074149131775,\n",
       "  0.9574074149131775,\n",
       "  0.9583333134651184,\n",
       "  0.9574074149131775,\n",
       "  0.9583333134651184,\n",
       "  0.9564814567565918,\n",
       "  0.9546296000480652,\n",
       "  0.9555555582046509,\n",
       "  0.9564814567565918,\n",
       "  0.9574074149131775,\n",
       "  0.9583333134651184,\n",
       "  0.9583333134651184,\n",
       "  0.9583333134651184,\n",
       "  0.960185170173645,\n",
       "  0.9583333134651184,\n",
       "  0.9583333134651184,\n",
       "  0.9592592716217041,\n",
       "  0.9592592716217041,\n",
       "  0.9592592716217041,\n",
       "  0.9592592716217041,\n",
       "  0.9592592716217041,\n",
       "  0.9592592716217041,\n",
       "  0.9592592716217041,\n",
       "  0.9592592716217041,\n",
       "  0.9583333134651184,\n",
       "  0.9583333134651184,\n",
       "  0.9592592716217041,\n",
       "  0.9583333134651184,\n",
       "  0.9592592716217041,\n",
       "  0.9583333134651184,\n",
       "  0.9620370268821716,\n",
       "  0.9592592716217041,\n",
       "  0.9611111283302307,\n",
       "  0.9592592716217041,\n",
       "  0.9583333134651184,\n",
       "  0.9574074149131775,\n",
       "  0.9583333134651184,\n",
       "  0.9574074149131775,\n",
       "  0.9564814567565918,\n",
       "  0.9564814567565918,\n",
       "  0.9564814567565918,\n",
       "  0.9564814567565918,\n",
       "  0.9583333134651184,\n",
       "  0.9592592716217041,\n",
       "  0.960185170173645,\n",
       "  0.9592592716217041,\n",
       "  0.9629629850387573,\n",
       "  0.9555555582046509,\n",
       "  0.9583333134651184,\n",
       "  0.9555555582046509,\n",
       "  0.9583333134651184,\n",
       "  0.9583333134651184,\n",
       "  0.9564814567565918,\n",
       "  0.9583333134651184,\n",
       "  0.9592592716217041,\n",
       "  0.9583333134651184,\n",
       "  0.9611111283302307,\n",
       "  0.9592592716217041,\n",
       "  0.9611111283302307,\n",
       "  0.9629629850387573,\n",
       "  0.9638888835906982,\n",
       "  0.9638888835906982,\n",
       "  0.9648148417472839,\n",
       "  0.9657407402992249,\n",
       "  0.9675925970077515,\n",
       "  0.9675925970077515,\n",
       "  0.9685184955596924,\n",
       "  0.9675925970077515,\n",
       "  0.9685184955596924,\n",
       "  0.970370352268219,\n",
       "  0.9694444537162781,\n",
       "  0.9712963104248047,\n",
       "  0.9694444537162781,\n",
       "  0.9722222089767456,\n",
       "  0.9731481671333313,\n",
       "  0.9712963104248047],\n",
       " 'loss': [1.7894376516342163,\n",
       "  1.7798810005187988,\n",
       "  1.7731140851974487,\n",
       "  1.764983057975769,\n",
       "  1.7554031610488892,\n",
       "  1.7439496517181396,\n",
       "  1.7300901412963867,\n",
       "  1.7124884128570557,\n",
       "  1.6911553144454956,\n",
       "  1.6633967161178589,\n",
       "  1.630156397819519,\n",
       "  1.591739296913147,\n",
       "  1.5459272861480713,\n",
       "  1.4948880672454834,\n",
       "  1.4395440816879272,\n",
       "  1.378896713256836,\n",
       "  1.3187799453735352,\n",
       "  1.2638049125671387,\n",
       "  1.2129125595092773,\n",
       "  1.168758511543274,\n",
       "  1.1280628442764282,\n",
       "  1.0947877168655396,\n",
       "  1.0629005432128906,\n",
       "  1.032932162284851,\n",
       "  1.007045865058899,\n",
       "  0.9808844923973083,\n",
       "  0.9580556154251099,\n",
       "  0.9365744590759277,\n",
       "  0.9153927564620972,\n",
       "  0.8957011699676514,\n",
       "  0.878007709980011,\n",
       "  0.8607034087181091,\n",
       "  0.8443963527679443,\n",
       "  0.8283214569091797,\n",
       "  0.812886118888855,\n",
       "  0.7981649041175842,\n",
       "  0.7837075591087341,\n",
       "  0.7696173787117004,\n",
       "  0.7566013932228088,\n",
       "  0.743375301361084,\n",
       "  0.7303540110588074,\n",
       "  0.7170917987823486,\n",
       "  0.7040436267852783,\n",
       "  0.6918945908546448,\n",
       "  0.6798838973045349,\n",
       "  0.6677873134613037,\n",
       "  0.6567146182060242,\n",
       "  0.6455806493759155,\n",
       "  0.6347792744636536,\n",
       "  0.6241137981414795,\n",
       "  0.6134607195854187,\n",
       "  0.6032141447067261,\n",
       "  0.5935738682746887,\n",
       "  0.583767831325531,\n",
       "  0.5747566223144531,\n",
       "  0.5657310485839844,\n",
       "  0.5569643974304199,\n",
       "  0.5485562086105347,\n",
       "  0.5402753353118896,\n",
       "  0.5324912071228027,\n",
       "  0.5247231125831604,\n",
       "  0.5173164010047913,\n",
       "  0.510129451751709,\n",
       "  0.5031558275222778,\n",
       "  0.4961528778076172,\n",
       "  0.48918473720550537,\n",
       "  0.4825688600540161,\n",
       "  0.47621941566467285,\n",
       "  0.4697151184082031,\n",
       "  0.46354979276657104,\n",
       "  0.4572871923446655,\n",
       "  0.4510246515274048,\n",
       "  0.44497671723365784,\n",
       "  0.43922218680381775,\n",
       "  0.43337884545326233,\n",
       "  0.4277942180633545,\n",
       "  0.4225296378135681,\n",
       "  0.4172764718532562,\n",
       "  0.4121802747249603,\n",
       "  0.4073086380958557,\n",
       "  0.4025998115539551,\n",
       "  0.3979826867580414,\n",
       "  0.39347773790359497,\n",
       "  0.3892585039138794,\n",
       "  0.38492754101753235,\n",
       "  0.3808572292327881,\n",
       "  0.3769075572490692,\n",
       "  0.3730519115924835,\n",
       "  0.3692374527454376,\n",
       "  0.3655205965042114,\n",
       "  0.3619237244129181,\n",
       "  0.3581823706626892,\n",
       "  0.3549434542655945,\n",
       "  0.35167086124420166,\n",
       "  0.3482138514518738,\n",
       "  0.3450429141521454,\n",
       "  0.3418530523777008,\n",
       "  0.33871176838874817,\n",
       "  0.3356035649776459,\n",
       "  0.3327455520629883,\n",
       "  0.32971709966659546,\n",
       "  0.3268917202949524,\n",
       "  0.32391467690467834,\n",
       "  0.3209574520587921,\n",
       "  0.3182833790779114,\n",
       "  0.3154570758342743,\n",
       "  0.3127247989177704,\n",
       "  0.3103111684322357,\n",
       "  0.3076316714286804,\n",
       "  0.30519530177116394,\n",
       "  0.3027275502681732,\n",
       "  0.3001585304737091,\n",
       "  0.2978407144546509,\n",
       "  0.29554370045661926,\n",
       "  0.2931400239467621,\n",
       "  0.2908274829387665,\n",
       "  0.2884874641895294,\n",
       "  0.28631776571273804,\n",
       "  0.28420451283454895,\n",
       "  0.28202909231185913,\n",
       "  0.279880166053772,\n",
       "  0.2778483033180237,\n",
       "  0.27596455812454224,\n",
       "  0.27398380637168884,\n",
       "  0.27206388115882874,\n",
       "  0.2700715959072113,\n",
       "  0.26829448342323303,\n",
       "  0.2663465738296509,\n",
       "  0.26447978615760803,\n",
       "  0.2626858055591583,\n",
       "  0.26064759492874146,\n",
       "  0.25894129276275635,\n",
       "  0.257144033908844,\n",
       "  0.2555255889892578,\n",
       "  0.25358185172080994,\n",
       "  0.2519911229610443,\n",
       "  0.2502518594264984,\n",
       "  0.24869023263454437,\n",
       "  0.24711467325687408,\n",
       "  0.24539799988269806,\n",
       "  0.24383090436458588,\n",
       "  0.24226363003253937,\n",
       "  0.24074359238147736,\n",
       "  0.23920047283172607,\n",
       "  0.23789694905281067,\n",
       "  0.23629935085773468,\n",
       "  0.23486842215061188,\n",
       "  0.23348774015903473,\n",
       "  0.23193438351154327,\n",
       "  0.23059801757335663,\n",
       "  0.2290438860654831,\n",
       "  0.22769303619861603,\n",
       "  0.22634264826774597,\n",
       "  0.22484612464904785,\n",
       "  0.22375428676605225,\n",
       "  0.2223513275384903,\n",
       "  0.22103211283683777,\n",
       "  0.21977774798870087,\n",
       "  0.21848642826080322,\n",
       "  0.21724383533000946,\n",
       "  0.2160179764032364,\n",
       "  0.2145894467830658,\n",
       "  0.21359539031982422,\n",
       "  0.2124042510986328,\n",
       "  0.2110804170370102,\n",
       "  0.21015864610671997,\n",
       "  0.20885631442070007,\n",
       "  0.20780068635940552,\n",
       "  0.2066989690065384,\n",
       "  0.20573849976062775,\n",
       "  0.20457470417022705,\n",
       "  0.2034926414489746,\n",
       "  0.20230360329151154,\n",
       "  0.2011083960533142,\n",
       "  0.20007608830928802,\n",
       "  0.1991431564092636,\n",
       "  0.1978958696126938,\n",
       "  0.1970146745443344,\n",
       "  0.1957107037305832,\n",
       "  0.19487743079662323,\n",
       "  0.19382965564727783,\n",
       "  0.19294026494026184,\n",
       "  0.19191506505012512,\n",
       "  0.19092974066734314,\n",
       "  0.18989402055740356,\n",
       "  0.18892383575439453,\n",
       "  0.187856063246727,\n",
       "  0.18714264035224915,\n",
       "  0.18613363802433014,\n",
       "  0.18524406850337982,\n",
       "  0.18436947464942932,\n",
       "  0.18350815773010254,\n",
       "  0.18268857896327972,\n",
       "  0.18182425200939178,\n",
       "  0.1809258610010147,\n",
       "  0.17997664213180542,\n",
       "  0.17932863533496857,\n",
       "  0.17834174633026123,\n",
       "  0.17770645022392273,\n",
       "  0.17683856189250946,\n",
       "  0.17603471875190735,\n",
       "  0.17534296214580536,\n",
       "  0.17450392246246338,\n",
       "  0.1734929233789444,\n",
       "  0.17300598323345184,\n",
       "  0.17207275331020355,\n",
       "  0.17146389186382294,\n",
       "  0.17070379853248596,\n",
       "  0.1700398325920105,\n",
       "  0.16935916244983673,\n",
       "  0.1688629686832428,\n",
       "  0.16781868040561676,\n",
       "  0.1668398082256317,\n",
       "  0.1664522886276245,\n",
       "  0.16576124727725983,\n",
       "  0.16518492996692657,\n",
       "  0.16456007957458496,\n",
       "  0.16368260979652405,\n",
       "  0.1629931479692459,\n",
       "  0.16239097714424133,\n",
       "  0.16172108054161072,\n",
       "  0.16098734736442566,\n",
       "  0.16044388711452484,\n",
       "  0.15997684001922607,\n",
       "  0.159311905503273,\n",
       "  0.1588304340839386,\n",
       "  0.15803393721580505,\n",
       "  0.15699627995491028,\n",
       "  0.156615749001503,\n",
       "  0.15624722838401794,\n",
       "  0.1557837575674057,\n",
       "  0.15514427423477173,\n",
       "  0.1541881412267685,\n",
       "  0.15337520837783813,\n",
       "  0.1531408131122589,\n",
       "  0.15249711275100708,\n",
       "  0.15156693756580353,\n",
       "  0.1510746330022812,\n",
       "  0.150661438703537,\n",
       "  0.14978991448879242,\n",
       "  0.14931520819664001,\n",
       "  0.1490553468465805,\n",
       "  0.14863461256027222,\n",
       "  0.14784203469753265,\n",
       "  0.1472736895084381,\n",
       "  0.14654980599880219,\n",
       "  0.1459336280822754,\n",
       "  0.14546790719032288,\n",
       "  0.14492635428905487,\n",
       "  0.14428630471229553,\n",
       "  0.14419563114643097,\n",
       "  0.14358380436897278,\n",
       "  0.14290596544742584,\n",
       "  0.14222389459609985,\n",
       "  0.14222240447998047,\n",
       "  0.14211887121200562,\n",
       "  0.14166207611560822,\n",
       "  0.14099092781543732,\n",
       "  0.14014509320259094,\n",
       "  0.14001479744911194,\n",
       "  0.13915519416332245,\n",
       "  0.13925586640834808,\n",
       "  0.13930226862430573,\n",
       "  0.13900305330753326,\n",
       "  0.13889408111572266,\n",
       "  0.13921470940113068,\n",
       "  0.1402391493320465,\n",
       "  0.1412375420331955,\n",
       "  0.14171196520328522,\n",
       "  0.1418064385652542,\n",
       "  0.14104148745536804,\n",
       "  0.1412154883146286,\n",
       "  0.14062513411045074,\n",
       "  0.1405980885028839,\n",
       "  0.13863788545131683,\n",
       "  0.13721893727779388,\n",
       "  0.13556931912899017,\n",
       "  0.13417313992977142,\n",
       "  0.1325490027666092,\n",
       "  0.13140597939491272,\n",
       "  0.13050004839897156,\n",
       "  0.12942837178707123,\n",
       "  0.12818241119384766,\n",
       "  0.12727811932563782,\n",
       "  0.12629906833171844,\n",
       "  0.12502430379390717,\n",
       "  0.12343690544366837,\n",
       "  0.12226563692092896,\n",
       "  0.12122387439012527,\n",
       "  0.11996574699878693,\n",
       "  0.11894261091947556,\n",
       "  0.1179814338684082,\n",
       "  0.11781191825866699,\n",
       "  0.11674362421035767,\n",
       "  0.11619649082422256,\n",
       "  0.11505787819623947,\n",
       "  0.1142999678850174,\n",
       "  0.11359777301549911,\n",
       "  0.1127050593495369,\n",
       "  0.11224815249443054],\n",
       " 'val_accuracy': [0.2083333283662796,\n",
       "  0.2083333283662796,\n",
       "  0.22499999403953552,\n",
       "  0.34166666865348816,\n",
       "  0.38333332538604736,\n",
       "  0.42500001192092896,\n",
       "  0.4583333432674408,\n",
       "  0.4749999940395355,\n",
       "  0.46666666865348816,\n",
       "  0.4833333194255829,\n",
       "  0.4749999940395355,\n",
       "  0.4749999940395355,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5583333373069763,\n",
       "  0.574999988079071,\n",
       "  0.574999988079071,\n",
       "  0.574999988079071,\n",
       "  0.574999988079071,\n",
       "  0.6166666746139526,\n",
       "  0.625,\n",
       "  0.6166666746139526,\n",
       "  0.6583333611488342,\n",
       "  0.6499999761581421,\n",
       "  0.6333333253860474,\n",
       "  0.6416666507720947,\n",
       "  0.6583333611488342,\n",
       "  0.6666666865348816,\n",
       "  0.6833333373069763,\n",
       "  0.6916666626930237,\n",
       "  0.6916666626930237,\n",
       "  0.699999988079071,\n",
       "  0.6916666626930237,\n",
       "  0.6916666626930237,\n",
       "  0.7083333134651184,\n",
       "  0.7250000238418579,\n",
       "  0.7250000238418579,\n",
       "  0.7416666746139526,\n",
       "  0.7583333253860474,\n",
       "  0.7583333253860474,\n",
       "  0.7583333253860474,\n",
       "  0.7416666746139526,\n",
       "  0.7416666746139526,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.7583333253860474,\n",
       "  0.7666666507720947,\n",
       "  0.7666666507720947,\n",
       "  0.7749999761581421,\n",
       "  0.7833333611488342,\n",
       "  0.7833333611488342,\n",
       "  0.7833333611488342,\n",
       "  0.7833333611488342,\n",
       "  0.7833333611488342,\n",
       "  0.7833333611488342,\n",
       "  0.7833333611488342,\n",
       "  0.7916666865348816,\n",
       "  0.7916666865348816,\n",
       "  0.7916666865348816,\n",
       "  0.7916666865348816,\n",
       "  0.7916666865348816,\n",
       "  0.7916666865348816,\n",
       "  0.7916666865348816,\n",
       "  0.7916666865348816,\n",
       "  0.7916666865348816,\n",
       "  0.7916666865348816,\n",
       "  0.800000011920929,\n",
       "  0.7916666865348816,\n",
       "  0.7916666865348816,\n",
       "  0.7916666865348816,\n",
       "  0.7916666865348816,\n",
       "  0.800000011920929,\n",
       "  0.800000011920929,\n",
       "  0.8083333373069763,\n",
       "  0.8083333373069763,\n",
       "  0.8083333373069763,\n",
       "  0.8166666626930237,\n",
       "  0.824999988079071,\n",
       "  0.824999988079071,\n",
       "  0.824999988079071,\n",
       "  0.824999988079071,\n",
       "  0.8333333134651184,\n",
       "  0.8416666388511658,\n",
       "  0.8500000238418579,\n",
       "  0.8416666388511658,\n",
       "  0.8416666388511658,\n",
       "  0.8416666388511658,\n",
       "  0.8416666388511658,\n",
       "  0.8416666388511658,\n",
       "  0.8416666388511658,\n",
       "  0.8416666388511658,\n",
       "  0.8416666388511658,\n",
       "  0.8416666388511658,\n",
       "  0.8416666388511658,\n",
       "  0.8416666388511658,\n",
       "  0.8416666388511658,\n",
       "  0.8416666388511658,\n",
       "  0.8416666388511658,\n",
       "  0.8416666388511658,\n",
       "  0.8500000238418579,\n",
       "  0.8416666388511658,\n",
       "  0.8500000238418579,\n",
       "  0.8500000238418579,\n",
       "  0.8583333492279053,\n",
       "  0.8583333492279053,\n",
       "  0.8666666746139526,\n",
       "  0.8583333492279053,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.875,\n",
       "  0.8666666746139526,\n",
       "  0.875,\n",
       "  0.875,\n",
       "  0.8833333253860474,\n",
       "  0.8833333253860474,\n",
       "  0.8833333253860474,\n",
       "  0.8833333253860474,\n",
       "  0.8833333253860474,\n",
       "  0.8833333253860474,\n",
       "  0.8833333253860474,\n",
       "  0.8833333253860474,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.9083333611488342,\n",
       "  0.8916666507720947,\n",
       "  0.9083333611488342,\n",
       "  0.8916666507720947,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9083333611488342,\n",
       "  0.8916666507720947,\n",
       "  0.8833333253860474,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8833333253860474,\n",
       "  0.8916666507720947,\n",
       "  0.8999999761581421,\n",
       "  0.8916666507720947,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.8999999761581421,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9083333611488342,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816],\n",
       " 'val_loss': [1.781013011932373,\n",
       "  1.7756695747375488,\n",
       "  1.7691243886947632,\n",
       "  1.7604457139968872,\n",
       "  1.7504068613052368,\n",
       "  1.7379183769226074,\n",
       "  1.7213023900985718,\n",
       "  1.7026952505111694,\n",
       "  1.6778465509414673,\n",
       "  1.6468454599380493,\n",
       "  1.6113905906677246,\n",
       "  1.5706952810287476,\n",
       "  1.5220413208007812,\n",
       "  1.472773790359497,\n",
       "  1.4172803163528442,\n",
       "  1.3604789972305298,\n",
       "  1.3114705085754395,\n",
       "  1.2611933946609497,\n",
       "  1.223876714706421,\n",
       "  1.1869056224822998,\n",
       "  1.149204969406128,\n",
       "  1.1249620914459229,\n",
       "  1.0911649465560913,\n",
       "  1.066294550895691,\n",
       "  1.0434502363204956,\n",
       "  1.0188333988189697,\n",
       "  0.9978494048118591,\n",
       "  0.9774841070175171,\n",
       "  0.9559219479560852,\n",
       "  0.9384537935256958,\n",
       "  0.9207221269607544,\n",
       "  0.9049299955368042,\n",
       "  0.888992428779602,\n",
       "  0.8739811182022095,\n",
       "  0.8591500520706177,\n",
       "  0.8446958065032959,\n",
       "  0.8308612108230591,\n",
       "  0.8178150057792664,\n",
       "  0.8058627843856812,\n",
       "  0.793158233165741,\n",
       "  0.7817507386207581,\n",
       "  0.7704060673713684,\n",
       "  0.7595860958099365,\n",
       "  0.7490264177322388,\n",
       "  0.737576425075531,\n",
       "  0.7267506718635559,\n",
       "  0.7158863544464111,\n",
       "  0.7058249115943909,\n",
       "  0.6949516534805298,\n",
       "  0.6848956346511841,\n",
       "  0.6752606630325317,\n",
       "  0.6658623814582825,\n",
       "  0.6563937067985535,\n",
       "  0.6469313502311707,\n",
       "  0.6379919052124023,\n",
       "  0.6288639307022095,\n",
       "  0.6204332113265991,\n",
       "  0.6122860312461853,\n",
       "  0.6044117212295532,\n",
       "  0.5970532894134521,\n",
       "  0.5894293189048767,\n",
       "  0.5828169584274292,\n",
       "  0.5767784118652344,\n",
       "  0.5705069303512573,\n",
       "  0.5644053220748901,\n",
       "  0.5583695769309998,\n",
       "  0.5525582432746887,\n",
       "  0.5465666651725769,\n",
       "  0.540332019329071,\n",
       "  0.5344193577766418,\n",
       "  0.5283063054084778,\n",
       "  0.5229486227035522,\n",
       "  0.5173748135566711,\n",
       "  0.5119574666023254,\n",
       "  0.5061704516410828,\n",
       "  0.501257061958313,\n",
       "  0.4963222146034241,\n",
       "  0.49127161502838135,\n",
       "  0.48703962564468384,\n",
       "  0.48220425844192505,\n",
       "  0.47795432806015015,\n",
       "  0.4735625982284546,\n",
       "  0.46945446729660034,\n",
       "  0.4653826057910919,\n",
       "  0.461191862821579,\n",
       "  0.4574204087257385,\n",
       "  0.45360469818115234,\n",
       "  0.4499841630458832,\n",
       "  0.44604527950286865,\n",
       "  0.44187310338020325,\n",
       "  0.4381333589553833,\n",
       "  0.434919536113739,\n",
       "  0.4319174587726593,\n",
       "  0.42822426557540894,\n",
       "  0.42557767033576965,\n",
       "  0.42122718691825867,\n",
       "  0.4193101227283478,\n",
       "  0.41583776473999023,\n",
       "  0.41280707716941833,\n",
       "  0.40954703092575073,\n",
       "  0.40690240263938904,\n",
       "  0.40368106961250305,\n",
       "  0.4008931815624237,\n",
       "  0.39834317564964294,\n",
       "  0.3953569531440735,\n",
       "  0.3921842873096466,\n",
       "  0.38967522978782654,\n",
       "  0.3870491087436676,\n",
       "  0.3842601180076599,\n",
       "  0.38157692551612854,\n",
       "  0.37921658158302307,\n",
       "  0.37678688764572144,\n",
       "  0.37422335147857666,\n",
       "  0.37246546149253845,\n",
       "  0.36950233578681946,\n",
       "  0.3672143220901489,\n",
       "  0.3646663725376129,\n",
       "  0.3627932369709015,\n",
       "  0.3605087399482727,\n",
       "  0.35838380455970764,\n",
       "  0.35650578141212463,\n",
       "  0.35397523641586304,\n",
       "  0.35276171565055847,\n",
       "  0.3497399091720581,\n",
       "  0.3478473424911499,\n",
       "  0.3458053469657898,\n",
       "  0.3433716595172882,\n",
       "  0.34169596433639526,\n",
       "  0.3388761281967163,\n",
       "  0.3377450406551361,\n",
       "  0.33510512113571167,\n",
       "  0.3337688446044922,\n",
       "  0.331680566072464,\n",
       "  0.33030250668525696,\n",
       "  0.32831621170043945,\n",
       "  0.32651254534721375,\n",
       "  0.32498735189437866,\n",
       "  0.32283467054367065,\n",
       "  0.3218362033367157,\n",
       "  0.31960251927375793,\n",
       "  0.31782981753349304,\n",
       "  0.31646302342414856,\n",
       "  0.31503283977508545,\n",
       "  0.3133172392845154,\n",
       "  0.3118351697921753,\n",
       "  0.3105107545852661,\n",
       "  0.30824244022369385,\n",
       "  0.3070829510688782,\n",
       "  0.3056240677833557,\n",
       "  0.30424442887306213,\n",
       "  0.3031589388847351,\n",
       "  0.30139055848121643,\n",
       "  0.30059120059013367,\n",
       "  0.29862987995147705,\n",
       "  0.29766908288002014,\n",
       "  0.29652610421180725,\n",
       "  0.2951461374759674,\n",
       "  0.2938727140426636,\n",
       "  0.29232022166252136,\n",
       "  0.2909267544746399,\n",
       "  0.29006195068359375,\n",
       "  0.28861674666404724,\n",
       "  0.2876998484134674,\n",
       "  0.2863740026950836,\n",
       "  0.28525975346565247,\n",
       "  0.2841796278953552,\n",
       "  0.2830561101436615,\n",
       "  0.2817969024181366,\n",
       "  0.2807941138744354,\n",
       "  0.2800520658493042,\n",
       "  0.2786014676094055,\n",
       "  0.2777113616466522,\n",
       "  0.276603639125824,\n",
       "  0.2754143476486206,\n",
       "  0.2744763195514679,\n",
       "  0.27360960841178894,\n",
       "  0.27295905351638794,\n",
       "  0.27250564098358154,\n",
       "  0.2714783847332001,\n",
       "  0.27066829800605774,\n",
       "  0.2698743939399719,\n",
       "  0.2692093849182129,\n",
       "  0.2684258818626404,\n",
       "  0.267119437456131,\n",
       "  0.2668629586696625,\n",
       "  0.26586300134658813,\n",
       "  0.26445186138153076,\n",
       "  0.2642793357372284,\n",
       "  0.26340827345848083,\n",
       "  0.26239779591560364,\n",
       "  0.2616042196750641,\n",
       "  0.2609197497367859,\n",
       "  0.26043257117271423,\n",
       "  0.260114848613739,\n",
       "  0.25918230414390564,\n",
       "  0.2583584785461426,\n",
       "  0.2584831714630127,\n",
       "  0.2573797106742859,\n",
       "  0.2575014531612396,\n",
       "  0.2562868297100067,\n",
       "  0.2568102777004242,\n",
       "  0.2546418607234955,\n",
       "  0.2560499608516693,\n",
       "  0.2536456286907196,\n",
       "  0.2551869750022888,\n",
       "  0.2532884180545807,\n",
       "  0.2541327476501465,\n",
       "  0.2527559697628021,\n",
       "  0.2532309889793396,\n",
       "  0.25252872705459595,\n",
       "  0.25125542283058167,\n",
       "  0.2536509335041046,\n",
       "  0.25232914090156555,\n",
       "  0.25244027376174927,\n",
       "  0.25266972184181213,\n",
       "  0.2513390779495239,\n",
       "  0.25293034315109253,\n",
       "  0.2513352930545807,\n",
       "  0.2525225281715393,\n",
       "  0.2525196075439453,\n",
       "  0.25265824794769287,\n",
       "  0.2521800398826599,\n",
       "  0.2519504427909851,\n",
       "  0.2515791058540344,\n",
       "  0.25436389446258545,\n",
       "  0.25147852301597595,\n",
       "  0.25376006960868835,\n",
       "  0.25343677401542664,\n",
       "  0.25250428915023804,\n",
       "  0.251207172870636,\n",
       "  0.25300517678260803,\n",
       "  0.2529297173023224,\n",
       "  0.2540959417819977,\n",
       "  0.25287696719169617,\n",
       "  0.25256580114364624,\n",
       "  0.2547452747821808,\n",
       "  0.25292733311653137,\n",
       "  0.2534940838813782,\n",
       "  0.25354015827178955,\n",
       "  0.2526070773601532,\n",
       "  0.25428086519241333,\n",
       "  0.25456756353378296,\n",
       "  0.25476399064064026,\n",
       "  0.2539021670818329,\n",
       "  0.25415462255477905,\n",
       "  0.2537233531475067,\n",
       "  0.25400441884994507,\n",
       "  0.25374144315719604,\n",
       "  0.253782719373703,\n",
       "  0.2543717324733734,\n",
       "  0.2541961669921875,\n",
       "  0.25515714287757874,\n",
       "  0.25365233421325684,\n",
       "  0.2538422644138336,\n",
       "  0.25388646125793457,\n",
       "  0.25409603118896484,\n",
       "  0.2535392940044403,\n",
       "  0.2537137567996979,\n",
       "  0.251895934343338,\n",
       "  0.2523384094238281,\n",
       "  0.2521946132183075,\n",
       "  0.2520737051963806,\n",
       "  0.25233936309814453,\n",
       "  0.2530467212200165,\n",
       "  0.2564481794834137,\n",
       "  0.2608686685562134,\n",
       "  0.27143800258636475,\n",
       "  0.27353546023368835,\n",
       "  0.2785743176937103,\n",
       "  0.28111550211906433,\n",
       "  0.27924248576164246,\n",
       "  0.2847961187362671,\n",
       "  0.28455984592437744,\n",
       "  0.2842184603214264,\n",
       "  0.2806451618671417,\n",
       "  0.27830711007118225,\n",
       "  0.2763744294643402,\n",
       "  0.27321872115135193,\n",
       "  0.2715700566768646,\n",
       "  0.27097827196121216,\n",
       "  0.26874950528144836,\n",
       "  0.26806360483169556,\n",
       "  0.26596373319625854,\n",
       "  0.26612821221351624,\n",
       "  0.26441994309425354,\n",
       "  0.26373419165611267,\n",
       "  0.2643622159957886,\n",
       "  0.26473790407180786,\n",
       "  0.2642125189304352,\n",
       "  0.26585400104522705,\n",
       "  0.26545238494873047,\n",
       "  0.26870912313461304,\n",
       "  0.26989951729774475,\n",
       "  0.26898106932640076,\n",
       "  0.27060651779174805,\n",
       "  0.2673768997192383,\n",
       "  0.2704113721847534,\n",
       "  0.2682580053806305,\n",
       "  0.26887163519859314,\n",
       "  0.27054911851882935]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now visualize the loss over time using `history.history`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/pandas/core/frame.py:5039: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0, 'Epoch'), Text(0, 0.5, 'Accuracy')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The history.history[\"loss\"] entry is a dictionary with as many values as epochs that the\n",
    "# model was trained on. \n",
    "df_loss_acc = pd.DataFrame(history.history)\n",
    "df_loss= df_loss_acc[['loss','val_loss']]\n",
    "df_loss.rename(columns={'loss':'train','val_loss':'validation'},inplace=True)\n",
    "df_acc= df_loss_acc[['accuracy','val_accuracy']]\n",
    "df_acc.rename(columns={'accuracy':'train','val_accuracy':'validation'},inplace=True)\n",
    "df_loss.plot(title='Model loss',figsize=(12,8)).set(xlabel='Epoch',ylabel='Loss')\n",
    "df_acc.plot(title='Model Accuracy',figsize=(12,8)).set(xlabel='Epoch',ylabel='Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations**! You've finished the assignment and built two models: One that recognizes  smiles, and another that recognizes SIGN language with almost 80% accuracy on the test set. In addition to that, you now also understand the applications of two Keras APIs: Sequential and Functional. Nicely done! \n",
    "\n",
    "By now, you know a bit about how the Functional API works and may have glimpsed the possibilities. In your next assignment, you'll really get a feel for its power when you get the opportunity to build a very deep ConvNet, using ResNets! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='6'></a>\n",
    "## 6 - Bibliography\n",
    "\n",
    "You're always encouraged to read the official documentation. To that end, you can find the docs for the Sequential and Functional APIs here: \n",
    "\n",
    "https://www.tensorflow.org/guide/keras/sequential_model\n",
    "\n",
    "https://www.tensorflow.org/guide/keras/functional"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "convolutional-neural-networks",
   "graded_item_id": "bwbJV",
   "launcher_item_id": "0TkXB"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
